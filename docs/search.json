[
  {
    "objectID": "Basic-Population-Genetics.html",
    "href": "Basic-Population-Genetics.html",
    "title": "Basic pop gen",
    "section": "",
    "text": "The module is aimed to give a brief background in population genetics.\nThis module will be taught by Kerstin Johannesson. No background reading is required for this module.\nThe lecture slides can be found here."
  },
  {
    "objectID": "Readings.html",
    "href": "Readings.html",
    "title": "Readings",
    "section": "",
    "text": "For each topic, there will be a required reading (or pre-class activity) and several optional readings.\nWe expect you to have read the required reading before the day. There will not be time during the week of the course to read new materials and therefore we highly suggest that you do these readings in advance of the course starting.\n\n\n\n\nNo background reading is required for this module.\n\n\n\nIf you are new to R, please attempt the following tutorials on your own. If you are experienced in R, skim through the tutorials and make sure that all the topics are familiar to you.\n\nRavinet’s introduction to R\nGoing further with R\n\nThrough this course, most of the examples you are likely to encounter will predominately use base R. However, learning Tidyverse syntax will make your life easier in the long run, especially if you are going to be manipulating spatial data.\n\n\n\nAs with R, you need to have some basic comfort and familiarity with bash. Either ensure you can complete the tutoirals on your own or attend this special Sunday session.\nSee activities and links on bash tutorial webpage.\n\n\n\n\n\n\n\n\n\nStorfer, A., Patton, A., & Fraik, A. K. (2018). Navigating the interface between landscape genetics and landscape genomics. Front Genet, 9, 68. doi:10.3389/fgene.2018.00068\n\n\n\n\n\nManel, S., Schwartz, M. K., Luikart, G., & Taberlet, P. (2003). Landscape genetics: combining landscape ecology and population genetics. Trends in Ecology and Evolution, 18(4), 189-197. doi:papers3://publication/doi/10.1016/S0169-5347(03)00008-9 This is the original paper defining landscape genetics as a field.\nRiginos, C., & Liggins, L. (2013). Seascape genetics: populations, individuals, and genes marooned and adrift. Geography Compass, 7(3), 197-216. doi:papers3://publication/doi/10.1111/gec3.12032 Discusses many ways that marine landscape genetics is distinct from terrestrial\nSelkoe, K. A., Scribner, K. T., & Galindo, H. M. (2016). Waterscape genetics – applications of landscape genetics to rivers, lakes, and seas. In N. Balkenhol, S. A. Cushman, A. Storfer, & L. P. Waits (Eds.), Landscape Genetics: Concepts, Methods, Applications (pp. 1-27): John Wiley & Sons, Ltd. Includes overviews on some of the contrasting features of marine and freshwater environments\nLiggins, L., Treml, E. A., & Riginos, C. (2019). Seascape genomics: contextualizing adaptive and neutral genomic variation in the ocean environment. Overviews on issues particular to marine studies\nBlanchet, S., Prunier, J. G., Paz-Vinas, I., Saint-Pe, K., Rey, O., Raffard, A., Mathieu-Begne, E., Loot, G., Fourtune, L., & Dubut, V. (2020). A river runs through it: The causes, consequences, and management of intraspecific diversity in river networks. Evolutionary Applications, 13(6), 1195-1213. doi:10.1111/eva.12941 Features and emerging conclusions from freshwater systems\n\n\n\n\n\nNo readings are required.\n\nThe best website explaining how to use spatial data in R is [Geocomputation with R, a book on geographic data analysis, visualization and modeling](https://r.geocompx.org)\nLeempoel, K., Duruz, S., Rochat, E., Widmer, I., Orozco-terWengel, P., & Joost, S. (2017). Simple rules for an efficient use of geographic information systems in molecular ecology. _Frontiers in Ecology and Evolution, 5_. doi:10.3389/fevo.2017.00033 *Reviews various approaches and tools, good list of terrestrial environmental data sources included in appendix*\n\n\n\n\n\n\n\n\n\n\nWaples, R. S., & Gaggiotti, O. E. (2006). What is a population? An empirical evaluation of some genetic methods for identifying the number of gene pools and their degree of connectivity. Molecular Ecology, 15(6), 1419-1439. doi:papers3://publication/doi/10.1111/j.1365-294X.2006.02890.x This study gives a nice example of what a population is.\n\n\n\n\n\nLeslie, S., Winney, B., Hellenthal, G., Davison, D., Boumertit, A., Day, T., Hutnik, K., Royrvik, E. C., Cunliffe, B., Wellcome Trust Case Control, C., International Multiple Sclerosis Genetics, C., Lawson, D. J., Falush, D., Freeman, C., Pirinen, M., Myers, S., Robinson, M., Donnelly, P., & Bodmer, W. (2015). The fine-scale genetic structure of the British population. Nature, 519(7543), 309-314. doi:10.1038/nature14230 This study is a nice example of how clustering can be used to study population structure.\nLinck, E., & Battey, C. J. (2019). Minor allele frequency thresholds strongly affect population structure inference with genomic data sets. Molecular Ecology Resources, 19(3), 639-647. doi:10.1111/1755-0998.12995\n\n\n\n\n\n\n\n\nCapblancq, T., & Forester, B. R. (2021). Redundancy analysis: A Swiss Army Knife for landscape genomics. Methods in Ecology and Evolution. doi:10.1111/2041-210x.13722 Clear explanations and worked examples that we will follow in class\n\n\n\n\n\nRellstab, C., Gugerli, F., Eckert, A. J., Hancock, A. M., & Holderegger, R. (2015). A practical guide to environmental association analysis in landscape genomics. Molecular Ecology, 24(17), 4348-4370. doi:papers3://publication/doi/10.1111/mec.13322 Highly recommend reading as a general overview to GEA/EEA analyses and concepts\nForester, B. R., Jones, M. R., Joost, S., Landguth, E. L., & Lasky, J. R. (2016). Detecting spatial genetic signatures of local adaptation in heterogeneous landscapes. Molecular Ecology, 25(1), 104-120. doi:papers3://publication/doi/10.1111/mec.13476 Evaluates various methods for finding genotype-by-environment associations and finds that RDA methods often best\nLasky, J. R., Josephs, E. B., & Morris, G. P. (2023). Genotype-environment associations to reveal the molecular basis of environmental adaptation. Plant Cell, 35, 125-138. doi:10.1093/plcell/koac267 Focusing on plants, reviews the strengths and shortcomings of GEA approaches\n\n\n\n\n\n\n\n\n\n\n\nSousa, V., Hey, J. Understanding the origin of species with genome-scale data: modelling gene flow.Nat Rev Genet 14, 404–414 (2013). https://doi.org/10.1038/nrg3446\nKelleher, J., Wong, Y., Wohns, A.W. et al. Inferring whole-genome histories in large population datasets. Nat Genet 51, 1330–1338 (2019). https://doi.org/10.1038/s41588-019-0483-y\n\n\n\n\n\nMeier, J.I., Sousa, V.C., Marques, D.A., Selz, O.M., Wagner, C.E., Excoffier, L. and Seehausen, O. (2017), Demographic modelling with whole-genome data reveals parallel origin of similar Pundamilia cichlid species after hybridization. Mol Ecol, 26: 123-141. https://doi.org/10.1111/mec.13838\n\n\n\n\n\n\n\n\n\n\n\nBeninde, J., Wittische, J., & Frantz, A. C. (2023). Quantifying uncertainty in inferences of landscape genetic resistance due to choice of individual-based genetic distance metric. Molecular Ecology Resources. doi:10.1111/1755-0998.13831\nPeterman, W. E. (2018). ResistanceGA: An R package for the optimization of resistance surfaces using genetic algorithms. Methods in Ecology and Evolution, 9(6), 1638-1647. doi:papers3://publication/doi/10.1111/2041-210X.12984\n\n\n\n\n\n\n\n\nFitzpatrick, M. C., & Keller, S. R. (2015). Ecological genomics meets community-level modelling of biodiversity: mapping the genomic landscape of current and future environmental adaptation. Ecol Lett, 18(1), 1-16. doi:papers3://publication/doi/10.1111/ele.12376\n\n\n\n\n\nMokany, K., Ware, C., Woolley, S. N. C., Ferrier, S., Fitzpatrick, Matthew C., & Bahn, V. (2022). A working guide to harnessing generalized dissimilarity modelling for biodiversity analysis and conservation assessment. Global Ecology and Biogeography, 31(4), 802-821. doi:10.1111/geb.13459. A worked example for GDM\nFerrier, S., Manion, G., Elith, J., & Richardson, K. (2007). Using generalized dissimilarity modelling to analyse and predict patterns of beta diversity in regional biodiversity assessment. Diversity and Distributions, 13(3), 252-264. doi:papers3://publication/doi/10.1111/j.1472-4642.2007.00341.x Original method for GDM\nEllis, N., Smith, S. J., & Pitcher, C. R. (2012). Gradient forests: calculating importance gradients on physical predictors. Ecology, 93(1), 156-168. doi:papers3://publication/uuid/06CCD6BA-6A4B-49EB-AE26-736E8A04B9C8 Original method for GF\n\n\n\n\n\n\n\n\nJahnke, M., Jonsson, P. R., Moksnes, P. O., Loo, L. O., Nilsson Jacobi, M., & Olsen, J. L. (2017). Seascape genetics and biophysical connectivity modelling support conservation of the seagrass Zostera marina in the Skagerrak-Kattegat region of the eastern North Sea. Evolutionary Applications, 1-46. doi:papers3://publication/doi/10.1111/eva.12589 Comprehensive review of studies pairing seascape genetic data with biophysical models\n\n\n\n\n\nBoulanger, E., Dalongeville, A., Andrello, M., Mouillot, D., & Manel, S. (2020). Spatial graphs highlight how multi‐generational dispersal shapes landscape genetic patterns. Ecography. doi:10.1111/ecog.05024\n\n\n\n\n\n\n\n\n\n\n\nCapblancq, T., Fitzpatrick, M. C., Bay, R. A., Exposito-Alonso, M., & Keller, S. R. (2020). Genomic prediction of (mal)adaptation across current and future climatic landscapes. Annual Review of Ecology, Evolution, and Systematics, 51(1), 245-269. doi:10.1146/annurev-ecolsys-020720-042553 Review of maladaptation and genomic offset concepts\n\n\n\n\n\nGougherty, A. V., Keller, S. R., & Fitzpatrick, M. C. (2021). Maladaptation, migration and extirpation fuel climate change risk in a forest tree species. Nat Clim Change, 11(2), 166-171. doi:10.1038/s41558-020-00968-6 Interesting conceptual example that integrates genomic offsets with dispersal capacity\nFitzpatrick, M. C., V. E. Chhatre, R. Y. Soolanayakanahally and S. R. Keller, 2021 Experimental support for genomic prediction of climate maladaptation using the machine learning approach Gradient Forests. Mol Ecol Resour 21: 2749-2765. One of the best examples of an empirical test of GEA predictions\n\n\n\n\n\nNo readings are required.\n\n\n\nLaruson, A. J., Fitzpatrick, M. C., Keller, S. R., Haller, B. C., & Lotterhos, K. E. (2022). Seeing the forest for the trees: Assessing genetic offset predictions from gradient forest. Evol Appl, 15(3), 403-416. doi:10.1111/eva.13354\nLotterhos, K. E. (2019). The effect of neutral recombination variation on genome scans for selection. G3 (Bethesda), 9(6), 1851-1867. doi:10.1534/g3.119.400088\nBierne, N., Gagnaire, P.-A., & David, P. (2013). The geography of introgression in a patchy environment and the thorn in the side of ecological speciation. Current Zoology, 59(1), 72-86. doi:papers3://publication/doi/10.1093/czoolo/59.1.72"
  },
  {
    "objectID": "Readings.html#readings-by-day-and-topic",
    "href": "Readings.html#readings-by-day-and-topic",
    "title": "Readings",
    "section": "",
    "text": "For each topic, there will be a required reading (or pre-class activity) and several optional readings.\nWe expect you to have read the required reading before the day. There will not be time during the week of the course to read new materials and therefore we highly suggest that you do these readings in advance of the course starting.\n\n\n\n\nNo background reading is required for this module.\n\n\n\nIf you are new to R, please attempt the following tutorials on your own. If you are experienced in R, skim through the tutorials and make sure that all the topics are familiar to you.\n\nRavinet’s introduction to R\nGoing further with R\n\nThrough this course, most of the examples you are likely to encounter will predominately use base R. However, learning Tidyverse syntax will make your life easier in the long run, especially if you are going to be manipulating spatial data.\n\n\n\nAs with R, you need to have some basic comfort and familiarity with bash. Either ensure you can complete the tutoirals on your own or attend this special Sunday session.\nSee activities and links on bash tutorial webpage.\n\n\n\n\n\n\n\n\n\nStorfer, A., Patton, A., & Fraik, A. K. (2018). Navigating the interface between landscape genetics and landscape genomics. Front Genet, 9, 68. doi:10.3389/fgene.2018.00068\n\n\n\n\n\nManel, S., Schwartz, M. K., Luikart, G., & Taberlet, P. (2003). Landscape genetics: combining landscape ecology and population genetics. Trends in Ecology and Evolution, 18(4), 189-197. doi:papers3://publication/doi/10.1016/S0169-5347(03)00008-9 This is the original paper defining landscape genetics as a field.\nRiginos, C., & Liggins, L. (2013). Seascape genetics: populations, individuals, and genes marooned and adrift. Geography Compass, 7(3), 197-216. doi:papers3://publication/doi/10.1111/gec3.12032 Discusses many ways that marine landscape genetics is distinct from terrestrial\nSelkoe, K. A., Scribner, K. T., & Galindo, H. M. (2016). Waterscape genetics – applications of landscape genetics to rivers, lakes, and seas. In N. Balkenhol, S. A. Cushman, A. Storfer, & L. P. Waits (Eds.), Landscape Genetics: Concepts, Methods, Applications (pp. 1-27): John Wiley & Sons, Ltd. Includes overviews on some of the contrasting features of marine and freshwater environments\nLiggins, L., Treml, E. A., & Riginos, C. (2019). Seascape genomics: contextualizing adaptive and neutral genomic variation in the ocean environment. Overviews on issues particular to marine studies\nBlanchet, S., Prunier, J. G., Paz-Vinas, I., Saint-Pe, K., Rey, O., Raffard, A., Mathieu-Begne, E., Loot, G., Fourtune, L., & Dubut, V. (2020). A river runs through it: The causes, consequences, and management of intraspecific diversity in river networks. Evolutionary Applications, 13(6), 1195-1213. doi:10.1111/eva.12941 Features and emerging conclusions from freshwater systems\n\n\n\n\n\nNo readings are required.\n\nThe best website explaining how to use spatial data in R is [Geocomputation with R, a book on geographic data analysis, visualization and modeling](https://r.geocompx.org)\nLeempoel, K., Duruz, S., Rochat, E., Widmer, I., Orozco-terWengel, P., & Joost, S. (2017). Simple rules for an efficient use of geographic information systems in molecular ecology. _Frontiers in Ecology and Evolution, 5_. doi:10.3389/fevo.2017.00033 *Reviews various approaches and tools, good list of terrestrial environmental data sources included in appendix*\n\n\n\n\n\n\n\n\n\n\nWaples, R. S., & Gaggiotti, O. E. (2006). What is a population? An empirical evaluation of some genetic methods for identifying the number of gene pools and their degree of connectivity. Molecular Ecology, 15(6), 1419-1439. doi:papers3://publication/doi/10.1111/j.1365-294X.2006.02890.x This study gives a nice example of what a population is.\n\n\n\n\n\nLeslie, S., Winney, B., Hellenthal, G., Davison, D., Boumertit, A., Day, T., Hutnik, K., Royrvik, E. C., Cunliffe, B., Wellcome Trust Case Control, C., International Multiple Sclerosis Genetics, C., Lawson, D. J., Falush, D., Freeman, C., Pirinen, M., Myers, S., Robinson, M., Donnelly, P., & Bodmer, W. (2015). The fine-scale genetic structure of the British population. Nature, 519(7543), 309-314. doi:10.1038/nature14230 This study is a nice example of how clustering can be used to study population structure.\nLinck, E., & Battey, C. J. (2019). Minor allele frequency thresholds strongly affect population structure inference with genomic data sets. Molecular Ecology Resources, 19(3), 639-647. doi:10.1111/1755-0998.12995\n\n\n\n\n\n\n\n\nCapblancq, T., & Forester, B. R. (2021). Redundancy analysis: A Swiss Army Knife for landscape genomics. Methods in Ecology and Evolution. doi:10.1111/2041-210x.13722 Clear explanations and worked examples that we will follow in class\n\n\n\n\n\nRellstab, C., Gugerli, F., Eckert, A. J., Hancock, A. M., & Holderegger, R. (2015). A practical guide to environmental association analysis in landscape genomics. Molecular Ecology, 24(17), 4348-4370. doi:papers3://publication/doi/10.1111/mec.13322 Highly recommend reading as a general overview to GEA/EEA analyses and concepts\nForester, B. R., Jones, M. R., Joost, S., Landguth, E. L., & Lasky, J. R. (2016). Detecting spatial genetic signatures of local adaptation in heterogeneous landscapes. Molecular Ecology, 25(1), 104-120. doi:papers3://publication/doi/10.1111/mec.13476 Evaluates various methods for finding genotype-by-environment associations and finds that RDA methods often best\nLasky, J. R., Josephs, E. B., & Morris, G. P. (2023). Genotype-environment associations to reveal the molecular basis of environmental adaptation. Plant Cell, 35, 125-138. doi:10.1093/plcell/koac267 Focusing on plants, reviews the strengths and shortcomings of GEA approaches\n\n\n\n\n\n\n\n\n\n\n\nSousa, V., Hey, J. Understanding the origin of species with genome-scale data: modelling gene flow.Nat Rev Genet 14, 404–414 (2013). https://doi.org/10.1038/nrg3446\nKelleher, J., Wong, Y., Wohns, A.W. et al. Inferring whole-genome histories in large population datasets. Nat Genet 51, 1330–1338 (2019). https://doi.org/10.1038/s41588-019-0483-y\n\n\n\n\n\nMeier, J.I., Sousa, V.C., Marques, D.A., Selz, O.M., Wagner, C.E., Excoffier, L. and Seehausen, O. (2017), Demographic modelling with whole-genome data reveals parallel origin of similar Pundamilia cichlid species after hybridization. Mol Ecol, 26: 123-141. https://doi.org/10.1111/mec.13838\n\n\n\n\n\n\n\n\n\n\n\nBeninde, J., Wittische, J., & Frantz, A. C. (2023). Quantifying uncertainty in inferences of landscape genetic resistance due to choice of individual-based genetic distance metric. Molecular Ecology Resources. doi:10.1111/1755-0998.13831\nPeterman, W. E. (2018). ResistanceGA: An R package for the optimization of resistance surfaces using genetic algorithms. Methods in Ecology and Evolution, 9(6), 1638-1647. doi:papers3://publication/doi/10.1111/2041-210X.12984\n\n\n\n\n\n\n\n\nFitzpatrick, M. C., & Keller, S. R. (2015). Ecological genomics meets community-level modelling of biodiversity: mapping the genomic landscape of current and future environmental adaptation. Ecol Lett, 18(1), 1-16. doi:papers3://publication/doi/10.1111/ele.12376\n\n\n\n\n\nMokany, K., Ware, C., Woolley, S. N. C., Ferrier, S., Fitzpatrick, Matthew C., & Bahn, V. (2022). A working guide to harnessing generalized dissimilarity modelling for biodiversity analysis and conservation assessment. Global Ecology and Biogeography, 31(4), 802-821. doi:10.1111/geb.13459. A worked example for GDM\nFerrier, S., Manion, G., Elith, J., & Richardson, K. (2007). Using generalized dissimilarity modelling to analyse and predict patterns of beta diversity in regional biodiversity assessment. Diversity and Distributions, 13(3), 252-264. doi:papers3://publication/doi/10.1111/j.1472-4642.2007.00341.x Original method for GDM\nEllis, N., Smith, S. J., & Pitcher, C. R. (2012). Gradient forests: calculating importance gradients on physical predictors. Ecology, 93(1), 156-168. doi:papers3://publication/uuid/06CCD6BA-6A4B-49EB-AE26-736E8A04B9C8 Original method for GF\n\n\n\n\n\n\n\n\nJahnke, M., Jonsson, P. R., Moksnes, P. O., Loo, L. O., Nilsson Jacobi, M., & Olsen, J. L. (2017). Seascape genetics and biophysical connectivity modelling support conservation of the seagrass Zostera marina in the Skagerrak-Kattegat region of the eastern North Sea. Evolutionary Applications, 1-46. doi:papers3://publication/doi/10.1111/eva.12589 Comprehensive review of studies pairing seascape genetic data with biophysical models\n\n\n\n\n\nBoulanger, E., Dalongeville, A., Andrello, M., Mouillot, D., & Manel, S. (2020). Spatial graphs highlight how multi‐generational dispersal shapes landscape genetic patterns. Ecography. doi:10.1111/ecog.05024\n\n\n\n\n\n\n\n\n\n\n\nCapblancq, T., Fitzpatrick, M. C., Bay, R. A., Exposito-Alonso, M., & Keller, S. R. (2020). Genomic prediction of (mal)adaptation across current and future climatic landscapes. Annual Review of Ecology, Evolution, and Systematics, 51(1), 245-269. doi:10.1146/annurev-ecolsys-020720-042553 Review of maladaptation and genomic offset concepts\n\n\n\n\n\nGougherty, A. V., Keller, S. R., & Fitzpatrick, M. C. (2021). Maladaptation, migration and extirpation fuel climate change risk in a forest tree species. Nat Clim Change, 11(2), 166-171. doi:10.1038/s41558-020-00968-6 Interesting conceptual example that integrates genomic offsets with dispersal capacity\nFitzpatrick, M. C., V. E. Chhatre, R. Y. Soolanayakanahally and S. R. Keller, 2021 Experimental support for genomic prediction of climate maladaptation using the machine learning approach Gradient Forests. Mol Ecol Resour 21: 2749-2765. One of the best examples of an empirical test of GEA predictions\n\n\n\n\n\nNo readings are required.\n\n\n\nLaruson, A. J., Fitzpatrick, M. C., Keller, S. R., Haller, B. C., & Lotterhos, K. E. (2022). Seeing the forest for the trees: Assessing genetic offset predictions from gradient forest. Evol Appl, 15(3), 403-416. doi:10.1111/eva.13354\nLotterhos, K. E. (2019). The effect of neutral recombination variation on genome scans for selection. G3 (Bethesda), 9(6), 1851-1867. doi:10.1534/g3.119.400088\nBierne, N., Gagnaire, P.-A., & David, P. (2013). The geography of introgression in a patchy environment and the thorn in the side of ecological speciation. Current Zoology, 59(1), 72-86. doi:papers3://publication/doi/10.1093/czoolo/59.1.72"
  },
  {
    "objectID": "maps-spatial-data.html",
    "href": "maps-spatial-data.html",
    "title": "Maps & spatial data",
    "section": "",
    "text": "Instructor: Riginos"
  },
  {
    "objectID": "maps-spatial-data.html#examining-and-creating-a-simple-features-objects",
    "href": "maps-spatial-data.html#examining-and-creating-a-simple-features-objects",
    "title": "Maps & spatial data",
    "section": "Examining and creating a simple features objects",
    "text": "Examining and creating a simple features objects\nTo start getting familiar with spatial objects, we will download a simple map of Sweden from natural earth. Take a quick look at this website to get a sense of all the wonderful data that are available here. (You are welcome to make a map of any country you like).\n\n#Extract information from natural earth\nSweden&lt;- ne_countries(country = \"sweden\", returnclass = \"sf\") \nplot(Sweden) \n#Surprised? We will come back to this.\n\n#Examine your new object \nclass(Sweden) #sf and data.frame\nSweden #tibble-like format!\n\nChecking spatial data using plots (often) is highly recommended. You should also check the class of the object. The challenge question below shows you how to handle data that are imported incorrectly.\n\nChallenge 1: Use subsetting commands to look at the first entry under the geometry column\n\n\nInstead of the command you used above, try Sweden2&lt;- ne_countries(country = \"sweden\"). Using class() look at how the object is described and compare to your original object. What has happened is that rather than create an sf object, the older format of sp has been created. See if you can convert Sweden2 to the sf format using the function st_as_sf().\n\nNotice that spatial features objects take the form of a tibble. This means that all your standard Tidyverse commands will work just fine (selecting, filtering, etc).\nYou will also notice that there is information about a “bounding box” and “CRS” in your sf version of Sweden where in the sp version of Sweden2 you saw “extent” and “crs”. We will come back to that! Otherwise this object mostly looks like a normal tibble with lots of columns, but there is one special column, labelled geometry. You will notice that for Sweden the geometry is described as a “MULTIPOLYGON”… more on this in a moment too.\n\nChallenge 2: Use subsetting commands to look at the first entry under the geometry column. Answers at end of this document, but you should be able to figure out these bits of code yourself! Try doing this using either base or tidy syntax, or both.\n\nYou should have an answer like this:\n\nPOLYGON ((11.02737 58.85615, 11.46827 59.43239, 12.30037 60.11793, 12.63115 61.29357, 11.99206 61.80036, 11.93057 63.12832……\n\nBesides being an eyesore to look at, you might notice some patterns: the odd entries look a lot like longitude values and the even entries look like latitudes… because they are! This POLYGON is composed of a series of points that are connected to form the Swedish coastline.\nWe can get a better feeling for this with a simple example where we construct a series of simple features (this example is borrowed from the sf vignette). Try to understand what is going on with each bit of code.\n\n## multipoints\np &lt;- rbind(c(3.2,4), c(3,4.6), c(3.8,4.4), c(3.5,3.8), c(3.4,3.6), c(3.9,4.5))  #makes a matrix of x & y value \nmp &lt;- st_multipoint(p)  #defining p as multipoint object\nplot(mp)  #you should see a series of points \n\n## linestring\ns1 &lt;- rbind(c(0,3),c(0,4),c(1,5),c(2,5))\nls &lt;- st_linestring(s1) # defining the linestring\nplot(ls) #you should see a series of lines\n\n## multilinestring\ns2 &lt;- rbind(c(0.2,3), c(0.2,4), c(1,4.8), c(2,4.8))\ns3 &lt;- rbind(c(0,4.4), c(0.6,5))\nmls &lt;- st_multilinestring(list(s1,s2,s3)) #notice the list function... #... applied to the matrices defining linestrings\nplot(mls)\n\n## multipolygon\np1 &lt;- rbind(c(0,0), c(1,0), c(3,2), c(2,4), c(1,4), c(0,0))\npol1 &lt;-st_polygon(list(p1))  \nplot(pol1)  \np2 &lt;- rbind(c(1,1), c(1,2), c(2,2), c(1,1))\npol2 &lt;-st_polygon(list(p2))\nplot(pol2)\n\n## What happens if we combine polygons?\npol &lt;-st_polygon(list(p1,p2))  #notice again the list function\nplot(pol)  # do you see 2 polygons?  \n# The second polygon is a \"hole\" in the outer polygon!\n\n## Now make it really messy!\np3 &lt;- rbind(c(3,0), c(4,0), c(4,1), c(3,1), c(3,0))\np4 &lt;- rbind(c(3.3,0.3), c(3.8,0.3), c(3.8,0.8), c(3.3,0.8), c(3.3,0.3))[5:1,]\np5 &lt;- rbind(c(3,3), c(4,2), c(4,3), c(3,3))\n# What do you think the following will look like? \n# Test your predictions using plot()\nmpol &lt;- st_multipolygon(list(list(p1,p2), list(p3,p4), list(p5))) \n\nTake a look again at your mpol object. As messy as this was to create, this is a pretty simple geometry and is captured by one MULTIPOLYGON entry. Go back now and look at mpol in its string form paying special attention to where the parentheses sit; their locations indicate if you have multiple polygons including holes within polygons.\n\nChallenge 3: Make a grey square with a square hole in the middle."
  },
  {
    "objectID": "maps-spatial-data.html#playing-with-some-real-spatial-data",
    "href": "maps-spatial-data.html#playing-with-some-real-spatial-data",
    "title": "Maps & spatial data",
    "section": "Playing with some real spatial data",
    "text": "Playing with some real spatial data\nOnly rarely do we need to manually create spatial feature. More likely we have data pre-packaged or we need to convert data. Use this link to download a csv file that has data for trees from the Bunya Mountains National Park in Queensland (one of my favorite places to go for a long weekend). These data come from my friend John Dwyer who is an awesome spatial ecologist (but is scared by genetics, sadly).\nImport this csv file making sure to fix the path and file name to match your set up. Before you convert the dataframe to a spatial features object take at look at how it is structured. Repeat this after you convert it.\n\n#load data\nBunyaMountainTrees&lt;-read_csv(\"./data/BunyaMountainTrees.csv\")\n\n#Convert the tibble to a simple features object, with x and y coordinates\n# Each row is a tree \nBunyaMountainTrees&lt;-st_as_sf(BunyaMountainTrees, coords = c(\"x\", \"y\")) \n\nWhat will plot(BunyaMountainTrees) look like? Surprised? (Does this remind you of what happened when you plotted Sweden?)\nTry plot(BunyaMountainTrees, max.plot = 28). Although this might be confusing at first, this is really super cool… you are seeing the various column variables displayed in the appropriate location by individual tree. For now, we can concentrate on the species variable only. Try plot(BunyaMountainTrees[\"species\"]). How cool is that! Let’s make this even better…\nWe will focus on ggplot solutions now, because the look nicer and are a bit easier.\n\nggplot(data = BunyaMountainTrees) +\n        geom_sf(aes(col=species))\n\n\nChallenge 4: Plot species identity for high-subplot 1, scaling the points by maximum tree diameter. Hint: Think about what units max_diam is in.\n\nNotice which tree is the largest? It is a Ficus obliqua, the small leaf or strangler fig. Because they wrap around other trees and have buttressed roots, they can get quite wide around.\n Now that your data in in the sf format, there are many other things you can do. For example, you could examine the distance between all pairs of trees.\n\ndistances&lt;-st_distance(BunyaMountainTrees, BunyaMountainTrees) #calculate distances, but this returns a symmetrical matrix\n\ndistances&lt;-distances[lower.tri(distances)] #lower.tri returns T/F values...see if you can follow the subsetting being used here\nggplot(data = as.data.frame(distances)) +\n  geom_histogram(mapping = aes(x = distances))\n\nKeep in mind that the data are bounded by the size of the subplot. But it is interesting that you do not get too many trees very close together…why do you think that might be?\nThis function is very useful - for example you might want to calculate distances between your sampling locations to look for patterns of isolation by distance. When your data are in an x-y plane, st_distance will return the Euclidean distance. When your data are projected (see next section), then st_distance will calculate the distance on Earth’s sphere. Most of the commands in sf will automatically adjust when your data are spherical. But, it is worth occasionally checking and when you see very odd results, keeping in mind that an inappropriate distance measure could be being used."
  },
  {
    "objectID": "maps-spatial-data.html#understanding-and-assigning-coordinate-reference-systems-crs",
    "href": "maps-spatial-data.html#understanding-and-assigning-coordinate-reference-systems-crs",
    "title": "Maps & spatial data",
    "section": "Understanding and assigning Coordinate Reference Systems (CRS)",
    "text": "Understanding and assigning Coordinate Reference Systems (CRS)\nTo start a deeper dive into CRS’s, go back to your now familiar Sweden object. Enter Sweden and also st_crs(Sweden).\nHere we can see that the projection is longlat (= longitude and latitude), with datum (starting point, or 0 value) at WGS84 (= equator with longitude set at the prime meridian or Greenwich, UK).\nWe can also find the bounding box or extent of the spatial object, which represents the rectangular shape in which our map sits, where x & y positions are reported using decimal longitude and latitude. Try st_boundary(Sweden))\nNote to your future self - longitude and latitude are very commonly reported incorrectly or in mixed formats. For example, rather than a decimal latitude of -38.2685, you might encounter 38° 16’ 6.6’’ S in degree-minute-second format. Or even worse you might get a mixture such as 38° 16.11’S ! Plot your data early on in any analysis to spot potential problems.\nWhat about BunyaMountainTrees? Try to see what CRS is assigned….nothing! And actually given that we were just using x and y coordinates in meters, that’s fine. But, if we wanted to plot the data on a map we would have problems.\nA file that accompanies BunyaMountainTrees is BunyaMountainSites. Import this and examine it. You might notice some funny variables called “easting” and “northing”; these are the positions of the plot sites in meters distant from a datum, a format called UTM or Universal Transverse Mercator. (A negative northing is in the southern direction.)\nIn order to attach the correct CRS details, however, we still need information on the projection…. Some further digging around on information provided by the authors gives us the following:\n\nLocation: Bunya Mountain National Park, Queensland Australia. Five areas of rainfortest or vine thicket were surveyed along a topographic moisture gradient: ‘high’ (easting = 359342, northing = 7027160) ‘low_east’ (365676, 7028551) ‘low_west’ (350888, 7030875) ‘mid_east’ (360196, 7027612) ‘mid_west’ (354971, 7031460) All eastings and northings in WGS84, zone 56.\n\nNotice “WGS84, zone 56”. (Although N and S are not stated, we can guess that the projection is S since the Bunya Mountains are in the southern hemisphere!) Once you find the projection description, google it, and you will be likely directed to the relevant EPSG site. Here, we can use either the EPSG number or (scrolling down the page) copy the PROJ.4 text.\nHere is how we assign the correct CRS to `BunyaMountainSites` and also turn it into an sf object.\n\nBunyaMountainSites &lt;-read_csv(\"./data/BunyaMountainSites.csv\")\n\nBunyaMountainSites_sf&lt;-st_as_sf(BunyaMountainSites, coords = c(\"easting\", \"northing\"))  #convert the tibble to an sf object \nst_crs(BunyaMountainSites_sf) &lt;-\"EPSG:32756\"\n#or\nst_crs(BunyaMountainSites_sf) &lt;-\"+proj=utm +zone=56 +south +datum=WGS84 +units=m +no_defs\"\n\n#or we can convert and assign CRS in one step:\nBunyaMountainSites_sf&lt;-st_as_sf(BunyaMountainSites_sf, coords = c(\"easting\", \"northing\"), crs=\"+proj=utm +zone=56 +south +datum=WGS84 +units=m +no_defs\")  \n\nThe website EPSG has lots of searchable information about CRS’s and projections; spend some time looking through their website. (Random trivia: EPSG stands for European Petroleum Survey Group. They created standards that have been widely adopted. EPSG is no longer associated with any industry group but the name persists.)"
  },
  {
    "objectID": "maps-spatial-data.html#transforming-and-reprojecting-crss",
    "href": "maps-spatial-data.html#transforming-and-reprojecting-crss",
    "title": "Maps & spatial data",
    "section": "Transforming and reprojecting CRS’s",
    "text": "Transforming and reprojecting CRS’s\nWe have succeeded in adding a CRS to our BunyaMountainSites_sf object…but is it correct? A handy quick check would be to plot it on our map of Australia. How can we do this? First, import a map of Australia as you did earlier for Sweden and use the st_crs() function to look at the CRS’s of each object…are they the same?\nTo convert the CRS of bunya_sites_sf to match Australia is quite straightforward using the st_transform() function that undertakes a lot of serious geometric calculations for us. We can do this a number of ways:\n\n# import map of Australia from natural earth\nAustralia&lt;- ne_countries(country = \"australia\", returnclass = \"sf\") \nst_crs(Australia)\n\n# transform CRS\nBunyaMountainSites.wgs84&lt;-st_transform(BunyaMountainSites_sf, crs=4326)\n#or\nBunyaMountainSites.wgs84&lt;-st_transform(BunyaMountainSites_sf, crs=\"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\")\n#or\nBunyaMountainSites.wgs84&lt;-st_transform(BunyaMountainSites_sf, st_crs(Australia))\n#All of these methods are equivalent\n\nNow to plot these points on the map…\n\nggplot(data = Australia) +\n  geom_sf() +  #background map needs to be first argument \n  geom_sf(data = BunyaMountainSites.wgs84, size = 4, shape = 23, fill = \"darkred\") #our sites plotted on top\n\nWhy have I had you play around with this dataset on Australian trees? Because this dataset presents some of the irregularities and problems you might face when finding spatial data. You will often have to do some detective work and guessing to find and assign the correct CRS. Always test by plotting your data!\nConsider three commonly used but different CRS’s:\n\nEPSG: 4326 = WGS84. For the whole earth, used by most GPS’s and Google Earth. Not equal area and technically not really projected. This one is an all-around compromise. It is centered on the equator and prime meridian\nEPSG:3006 = SWEREF99: This is for all of Sweden. It is a conformal projection that attempts to make both distances and area well represented. Good for making Swedish maps and Swedish focused analyses.\nLambert Equal Area Azimuthal = LAEA: equal area projection and can be centered where we choose.\n\nOur data is already in WGS84 but if we needed to define it the code would be:\nWGS&lt;-\"+proj=longlat +datum=WGS84 +no_defs\"\nThe code for SWEREF99 is: SWEREF99 &lt;- \"+proj=utm +zone=33 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs +type=crs\"\nAnd for LAEA centered on the WGS84 datum: LAEA &lt;- \"+proj=laea  +lat_0=0 +lon_0=0\" (to center in Sweden: laea &lt;- \"+proj=laea  +lat_0=16.321998712 +lon_0=62.38583179\")\nTo see what those different projections look like, we can got back to our map of Sweden. We can reproject the CRS as follows:\n\nWGS&lt;-\"+proj=longlat +datum=WGS84 +no_defs\"\n\nSWEREF99 &lt;- \"+proj=utm +zone=33 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs +type=crs\"\n\nLAEA &lt;- \"+proj=laea  +lat_0=16.321998712 +lon_0=62.38583179\"\n\nSweden.SWEREF99 &lt;-st_transform(Sweden, SWEREF99)\nSweden.LAEA&lt;-st_transform(Sweden, LAEA)\n\n\nChallenge 5: Plot your original Sweden WGS and two reprojected maps. Then, change the LAEA projection to be centred on the prime meridien and plot that map again.\n\nNote to your future self: Make sure that CRS are the same between objects that you are seeking to compare and map. It is easy to get caught out.\nAdd example of reading in river data"
  },
  {
    "objectID": "maps-spatial-data.html#cropping-a-raster",
    "href": "maps-spatial-data.html#cropping-a-raster",
    "title": "Maps & spatial data",
    "section": "Cropping a raster",
    "text": "Cropping a raster\nRasters can be manipulated in manners similar to sf objects. In the example that follows, we are going to crop the global SST data to match the spatial extent of our Sweden vector object.\n\n#first check that both objects have the same crs\nsame.crs(Sweden, SST)\n\n# crop based on the spatial extent of Sweden\nSST.sw&lt;-terra::crop(SST, Sweden)\n\n# plot to check\nggplot() +\n  geom_spatraster(data = SST.sw)\n\nObviously that crop is a bit too close. There are many solutions for how to do this, but I will show you a manual solution so you can understand the spatialExtent or bounding box of an spatial object.\n\n#diagnose the problem - look at the \"bounding box\" for the vector object\nst_bbox(Sweden)\n\n# and look at the \"extent\" for the raster\next(SST.sw)\n\n#Rounding error has resulted in ugliness!\n\n#manually set the extent to crop\nSST.sw&lt;-terra::crop(SST, c(4, 24, 55, 70))\n\n# plot to check\nggplot() +\n  geom_spatraster(data = SST.sw)"
  },
  {
    "objectID": "maps-spatial-data.html#reprojecting-a-raster",
    "href": "maps-spatial-data.html#reprojecting-a-raster",
    "title": "Maps & spatial data",
    "section": "Reprojecting a raster",
    "text": "Reprojecting a raster\nLike vector data, rasters can be reprojected. Try the following code to project SST.sw to the LAEA0 projection. Then plot it.\n\nLAEA0 &lt;- \"+proj=laea  +lat_0=0 +lon_0=0\" \n\n# raster reprojection\nSST.sw.laea&lt;-project(SST.sw, LAEA0)\n\nSurprised?\nEach time you reproject, however, you alter your raster. Therefore you should try to avoid doing this too much and it is generally best practice to reproject your vector data to match your raster’s CRS. (You can reproject vector objects back and forth endlessly without loosing information…why?)\nGeneral tips in working with rasters\n\nUse a coarse granularity of data to optimise your code and plotting and then for the final analyses (and graphics) use the finer resolution.\nReproject once only.\nProject before cropping."
  },
  {
    "objectID": "maps-spatial-data.html#working-with-spatial-data-generally",
    "href": "maps-spatial-data.html#working-with-spatial-data-generally",
    "title": "Maps & spatial data",
    "section": "Working with spatial data generally",
    "text": "Working with spatial data generally\nFantastic and comprehensive entry level open source book. Geocomputation with R\nGeneral explanations on using R for biological spatial data including remote sensing rspatial.org\nA series of well explained tutorials for making publication-ready maps:\n\nPart 1: Basics\nPart 2: Layers\nPart 3: Layouts\n\nAnother open source book: Spatial Data Science"
  },
  {
    "objectID": "maps-spatial-data.html#specific-r-package-support",
    "href": "maps-spatial-data.html#specific-r-package-support",
    "title": "Maps & spatial data",
    "section": "Specific R package support",
    "text": "Specific R package support\nsf package vignettes - these are rather technical\nmarmap package with excellent vignettes - an essential resource if using marine data that allows you to draw bathymetric maps"
  },
  {
    "objectID": "Teachers.html",
    "href": "Teachers.html",
    "title": "Meet your teachers",
    "section": "",
    "text": "(University of Queensland, guest professor at University of Gothenburg)"
  },
  {
    "objectID": "Teachers.html#cynthia-riginos",
    "href": "Teachers.html#cynthia-riginos",
    "title": "Meet your teachers",
    "section": "",
    "text": "(University of Queensland, guest professor at University of Gothenburg)"
  },
  {
    "objectID": "Teachers.html#anna-runemark",
    "href": "Teachers.html#anna-runemark",
    "title": "Meet your teachers",
    "section": "Anna Runemark",
    "text": "Anna Runemark\n(Lund University)"
  },
  {
    "objectID": "Teachers.html#mark-ravinet",
    "href": "Teachers.html#mark-ravinet",
    "title": "Meet your teachers",
    "section": "Mark Ravinet",
    "text": "Mark Ravinet\n(University of Nottingham)"
  },
  {
    "objectID": "Teachers.html#kerstin-johannesson",
    "href": "Teachers.html#kerstin-johannesson",
    "title": "Meet your teachers",
    "section": "Kerstin Johannesson",
    "text": "Kerstin Johannesson\n(University of Gothenburg, main organiser)"
  },
  {
    "objectID": "Teachers.html#per-jonsson",
    "href": "Teachers.html#per-jonsson",
    "title": "Meet your teachers",
    "section": "Per Jonsson",
    "text": "Per Jonsson\n(University of Gothenburg)"
  },
  {
    "objectID": "basic-bash.html",
    "href": "basic-bash.html",
    "title": "Basic Bash",
    "section": "",
    "text": "This module is an introduction to bash, covering the most basic concepts. For those that are new to bash, we recommend trying out an online tutorial for bash for beginners prior to the course in addition to this, for instance https://evomics.org/learning/unix-tutorial/Links\nThose with Windows computers will also need to prepare to be able to use a terminal on their computers, we provide background instructions.\nThe module will consist in a lecture and an exercise. We will also hand out IDs and give instructions for logging on to the Lund University server that will be used for all bash based teaching during this session.\nIf you encounter issues, please post questions on the course Slack channel"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About the course",
    "section": "",
    "text": "How spatial data on properties of terrestrial and marine environments can be combined with genomic data to gain an understanding of population structure, dispersal routes and patterns. And how such can facilitate appropriate and sustainable land and seabottom use and management."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "About the course",
    "section": "",
    "text": "How spatial data on properties of terrestrial and marine environments can be combined with genomic data to gain an understanding of population structure, dispersal routes and patterns. And how such can facilitate appropriate and sustainable land and seabottom use and management."
  },
  {
    "objectID": "index.html#teachers",
    "href": "index.html#teachers",
    "title": "About the course",
    "section": "Teachers",
    "text": "Teachers\nCynthia Riginos (University of Queensland, guest professor at University of Gothenburg)\nAnna Runemark (Lund University)\nMark Ravinet (University of Nottingham)\nKerstin Johannesson (University of Gothenburg, main organiser)\nPer Jonsson (University of Gothenburg)"
  },
  {
    "objectID": "index.html#dates",
    "href": "index.html#dates",
    "title": "About the course",
    "section": "Dates",
    "text": "Dates\n29th October to 4 November, 2023"
  },
  {
    "objectID": "index.html#venue",
    "href": "index.html#venue",
    "title": "About the course",
    "section": "Venue",
    "text": "Venue\nTjärnö Marine Laboratory, Strömstad, Sweden"
  },
  {
    "objectID": "index.html#credits",
    "href": "index.html#credits",
    "title": "About the course",
    "section": "Credits",
    "text": "Credits\n2.5 hp"
  },
  {
    "objectID": "index.html#friday-3rd-november",
    "href": "index.html#friday-3rd-november",
    "title": "About the course",
    "section": "Friday 3rd November",
    "text": "Friday 3rd November\n(meals and breaks same schedule as Sunday)\n09.00-12.00     More GEAs and genomic offsets (Cynthia)\n12.00-14.00     Lunch + walk & talk\n14.00-17.00     (Time permiting) Landscape genomics and genetic architectures\n17.00-18.00     Dinner\n19.00-23.00     Inhouse pub\n\nSaturday 4th November\nDepartures in the morning -sorry to see you go!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "RDA.html",
    "href": "RDA.html",
    "title": "Intro to RDA as a flexible tool",
    "section": "",
    "text": "Instructor: Riginos"
  },
  {
    "objectID": "RDA.html#geas-genotype-by-environment-associations",
    "href": "RDA.html#geas-genotype-by-environment-associations",
    "title": "Intro to RDA as a flexible tool",
    "section": "GEAs: Genotype-by-environment associations",
    "text": "GEAs: Genotype-by-environment associations\n( = environmental associations)\nFrom Monday:\n\nGenome-wide: related to demographic history, ecological speciation/diversification, isolation by environment\n\n\n\n\nIBE signals - Wang & Bradburd 2014\n\n\nWe will focus on this aspect today\n\nFinding loci contribute to heritable genetic variation of selected traits\n\n\n\n\nRellstab et al 2015 (Image modified from Sork et al 2013)\n\n\nWe will come back to this topic on Friday."
  },
  {
    "objectID": "RDA.html#pca---principal-components-analysis",
    "href": "RDA.html#pca---principal-components-analysis",
    "title": "Intro to RDA as a flexible tool",
    "section": "PCA - principal components analysis",
    "text": "PCA - principal components analysis\n\nNo predictive variables: unconstrained.\nFits a line through the data along an axis that maximizes the variance described by the first PC axis (PC1).\nFits the next line to maximize the variance described for the second PC axis (PC2) where PC1 and PC2 are orthogonal (their variances are not correlated).\nAnd so on.\nNote that this is a linear procedure: lines are being fitted.\nEigenvalues (\\(\\lambda\\)) describe the amount of variance explained by each eigenvector (= line = PC axis)\n\n\n\n\nPCA - Wagner & Fortin 2016"
  },
  {
    "objectID": "RDA.html#pcoa-or-pco-principal-coordinates-analysis",
    "href": "RDA.html#pcoa-or-pco-principal-coordinates-analysis",
    "title": "Intro to RDA as a flexible tool",
    "section": "PCoA or PCO: Principal coordinates analysis",
    "text": "PCoA or PCO: Principal coordinates analysis\n\nsame as metric multidimensional scaling\ntakes pairwise distances (\\(d_{ij}\\), sometimes called dissimilarities) between points and uses ordination to find axes that maximally explain dissimilarities\nPCoA on Euclidean distances is the same as PCA\nSometimes you get negative eigenvalues and have to use a correction\n(non metric multidimensional scaling is similar but does not require linear data)"
  },
  {
    "objectID": "RDA.html#example-from-capblancq-forester-2021---lodgepole-pine",
    "href": "RDA.html#example-from-capblancq-forester-2021---lodgepole-pine",
    "title": "Intro to RDA as a flexible tool",
    "section": "Example from Capblancq & Forester 2021 - lodgepole pine",
    "text": "Example from Capblancq & Forester 2021 - lodgepole pine\n\n\n\nCredit: Kevin Cass\n\n\n\nuse ~3000 “intergenic” SNPs as neutral loci (genotyped from 50K SNP chip)\ngeography, climate and neutral structure are all confounded\n\n\nGoals\n\nto undertake a GEA and ignore effect of geography+structure -&gt; possible false positives\nto undertake a GEA and remove geography+structure -&gt; possible false negatives\nThere is no clear solution to the problems of false positives and false negatives"
  },
  {
    "objectID": "RDA.html#data-preparation-for-rda",
    "href": "RDA.html#data-preparation-for-rda",
    "title": "Intro to RDA as a flexible tool",
    "section": "Data preparation for RDA",
    "text": "Data preparation for RDA\n\nget environmental variables and scale them to a mean of 0, SD = 1\ncategorical predictors can be used as dummy variables (0/1)\nlook for colinearity among variables - might remove variables with variance inflation factor greater than ?"
  },
  {
    "objectID": "RDA.html#variable-selection-with-forward-model-building",
    "href": "RDA.html#variable-selection-with-forward-model-building",
    "title": "Intro to RDA as a flexible tool",
    "section": "Variable selection with forward model building",
    "text": "Variable selection with forward model building\nBuild up a predictive model and assists with variable reduction\n\nTest significance of global model (= all variables)\nStart with “empty” model (= intercept only) and sequentially add variables\nTwo stopping criteria to avoid overfitting - end with either criterion\n\npermutation based significance test\nadjusted \\(R^2\\) from global model\n\n\n\n\n\nSimple RDA output - Capblancq & Forester 2021"
  },
  {
    "objectID": "RDA.html#further-resources",
    "href": "RDA.html#further-resources",
    "title": "Intro to RDA as a flexible tool",
    "section": "Further resources",
    "text": "Further resources\n\nThe absolutely go-to package in R for all ecological eigenanalysis is vegan. It is very well documented and has excellent vignettes that are well-worth working through.\nReally nice slide deck that demonstrates some vegan functions with excellent illustrations Intro to vegan\nAnother great slide deck that runs through RDA and associated vegan functions Redundancy Analysis"
  },
  {
    "objectID": "RDA.html#notes-developed-from",
    "href": "RDA.html#notes-developed-from",
    "title": "Intro to RDA as a flexible tool",
    "section": "Notes developed from:",
    "text": "Notes developed from:\n\n\nCapblancq, T., & Forester, B. R. (2021). Redundancy analysis: A Swiss Army Knife for landscape genomics. Methods in Ecology and Evolution. doi:10.1111/2041-210x.13722\n\n\n\n\nRellstab, C., Gugerli, F., Eckert, A. J., Hancock, A. M., & Holderegger, R. (2015). A practical guide to environmental association analysis in landscape genomics. Molecular Ecology, 24 (17), 4348-4370.\n\n\n\n\nWang, I. J., & Bradburd, G. S. (2014). Isolation by environment. Molecular Ecology, 23(23), 5649-5662. doi:papers3://publication/doi/10.1111/mec.12938\n\n\n\n\nZbinden, Z. D., Douglas, M. R., Chafin, T. K., & Douglas, M. E. (2022). Riverscape community genomics: A comparative analytical approach to identify common drivers of spatial structure. Molecular Ecology, 32, XXX-XXX. doi:10.1111/mec.16806"
  },
  {
    "objectID": "RDA.html#introduction",
    "href": "RDA.html#introduction",
    "title": "Intro to RDA as a flexible tool",
    "section": "Introduction",
    "text": "Introduction\n\nThis tutorial provides code and explanation associated with a review of the different applications of RDA in the field of landscape genomics written by Thibaut Capblancq & Brenna Forester (2021) Redundancy Analysis (RDA): a Swiss-army knife for landscape genomics.\n\n\nWe highly recommend the following book for those interested in RDA: Borcard D, Gillet F, Legendre P (2018) Numerical Ecology with R, 2nd edition.\n\n(Cynthia also endorses the same book)\n\nDatafiles\n\nClimatic variables\n\nThe values of 27 bioclimate variables were extracted for all 281 populations from the ClimateNA database for the period 1961-1990, and projections for 2050 and 2080. The projections are based on an ensemble of 15 AOGCMs using CMIP5.\n\nThese data have been compiled and projected into the WGS84 reference coordinate system following instructions from Capblancq & Forester and saved as a spatial raster.\n\nras_6190.rast = present day\n\n\n\nPopulation allele frequencies\nOriginal genetic data and metadata from Mahony et al. 2019, available here. SNP genotypes were derived for individual seedlings from 281 populations of lodgepole pine (Pinus contorta).\nPre-processing:\n\nCalled genotypes were recoded as numeric in order to run RDA using the vegan library. Although some other packages will conduct PCAs and RDAs, vegan is recommended. In the numeric formatting, 0 represents an individual homozygous for the major allele, 1 represents a heterozygote, and 2 is homozygous for the alternative allele.\nDataframes were subset to individuals with spatially relevant metadata.\nThe mean allele frequency per population (281 populations) was computed\nLoci with missing data from 12 or more populations were excluded\nFor population-by-locus combinations with NA values, the values were imputed as the median across all populations (cannot have missing data for PCA and RDA)\nMAFs &lt; 0.05 or &gt; 0.95 were excluded from full SNP data set (but not “neutral” SNPs)\n\nDatafiles\n\nAllFreq: 281 populations, 28658 loci\nAllFreq_neutral: 281 populations, 3936 loci\nPlSeedlots.csv: the geographic coordinates of each source population.\n\nLook at all these files using tools and techniques that you have learned. What is in the ras_6190.rast object? (try plotting it)\nSome comments from C & F:\n\nAn RDA model can either be conducted with individual-based genotypes (0, 1, 2 format) or population-based allele frequencies (ranging from 0 to 1). We decided here to work with allele frequencies for the main reason that several individuals were genotyped at each sampling site (i.e., source population) and experienced the exact same climatic conditions. Plus, the sample sizes varied across populations.\n\n\n(For full data set) SNPs with a minor allele frequency inferior to 5% were filtered out to avoid giving too much importance to rare alleles when looking for loci associated with environmental variation. Doing so means assuming that local adaptation is driven by consequent changes in adaptive allele frequency along environmental gradients.\n\n\n(For neutral data set) No filtering on MAF was applied here because small genetic variations are expected to be involved in differentiating neutral genetic groups.\n\n\n\n\nLoad libraries and data files\n\nlibrary(terra)\nlibrary(vegan)\nlibrary(corrplot)\n\n#Climate data\nras_6190&lt;-terra::rast(\"./home/data/ras_6190.tif\")\nnames(ras_6190) &lt;- c(\"AHM\",\"bFFP\",\"CMD\",\"DD_0\",\"DD_18\",\"DD18\",\"DD5\",\"eFFP\",\"EMT\", \"Eref\", \"EXT\", \"FFP\", \"MAP\", \"MAR\", \"MAT\", \"MCMT\", \"MSP\", \"MWMT\", \"NFFD\", \"PAS\", \"PPT_sm\", \"PPT_wt\", \"RH\", \"SHM\", \"Tave_sm\", \"Tave_wt\", \"TD\")\n\n# Genetic data\nload(\"./home/data/AllFreq.RData\")\nload(\"./home/data/Neutral.RData\")\n\n#Sampling sites\nCoordinates &lt;- read.table(\"./home/data/PlSeedlots.csv\", sep = \",\", header = T, row.names = 1)\n\n# Tidy up the coordinates data and check them\nCoordinates &lt;- Coordinates[match(row.names(AllFreq), Coordinates$id2, nomatch = 0),]\ncolnames(Coordinates) &lt;- c(\"Population\", \"Latitude\", \"Longitude\", \"Elevation\")\nCoordinates[1:5,]"
  },
  {
    "objectID": "RDA.html#preparing-data-for-rda",
    "href": "RDA.html#preparing-data-for-rda",
    "title": "Intro to RDA as a flexible tool",
    "section": "Preparing data for RDA",
    "text": "Preparing data for RDA\nA series of RDAs will be the heart of the analyses. Before you can do an RDA, however, you need to have all your data prepared and organised. The genetic data are already largely prepared, but some extra work is needed for the environmental data and for estimating neutral population structure.\n\nExtract environmental data from rasters and scale them\n\n#Extract environmental data from the sampling site locations\nEnv&lt;-extract(ras_6190, Coordinates[,3:2])\n\n# look at your extracted data\nEnv[1:5,1:8]\n\nEnv &lt;- scale(Env, center=TRUE, scale=TRUE) # center=TRUE, scale=TRUE are the defaults for scale()\n\nrow.names(Env) &lt;- c(Coordinates$Population)\n\n\n\nUse “neutral” SNPs to estimate population structure\n\nTo account for population structure in some of the following RDA-based procedures we conducted a principal component analysis (PCA) on the set of 3,934 intergenic SNPs and retained the first three PCs as proxy of population evolutionary history.\n\n\n## Running a PCA on neutral genetic markers\npca &lt;- rda(Neutral[,-1], scale=T) # PCA in vegan uses the rda() call without any predictors\n# scale = T will take care of scaling for you\n\nExamine the pca object (call pca and summary(pca)) - think about how many PC’s are informative. When you call pca you will see the formula, the “Inertia” and the Eigenvalues for the PC axes. Notice that all the Inertia is unconstrained. Later you will compare this to the full RDA output. Divide the Eigenvalue of PC1 but the total Inertia: this will be percent of variance explained by PC1. The “Species scores” are your column variables, which are loci in this case. The “Site scores” are row variables or populations. The values are loadings, which enable you to plot loci or populations in PC space.\nIf this were my data and analysis, I would plot the PCA at this point and make sure it all made sense.\n\nbiplot(pca, choices=c(1,2), scaling = \"symmetric\", type= c(\"points\", \"text\"))\n\nWhat I like to see in a pca is balanced clouds of points. If there is very little population structure, you might see one big cloud of points. If you have substantial structuring, there could be multiple clouds of points. Smears along a single axis (as we see here) are a bit worrisome especially if they do not make geographical sense. Another attribute to be aware of is that imputing allele frequencies can pull values to the middle. For the purposes of this tutorial, we will just continue, but in a real analysis I would try to understand my data at this point and make sure that there are no odd dynamics that might influence later analyses.\nPeople often use screeplots to look at variance and decide on the number of PCs to keep.\n\n# look at screeplot to decide importance\nscreeplot(pca, type = \"barplot\", npcs=10, main=\"PCA Eigenvalues\")\n\n\nBased on the screeplot, two or three PCs would be a reasonable set to retain as a proxy for neutral population structure in downstream analyses. In this case, we decided to keep the first three PCs.\n\nValues from these first three PCs can now be extracted. It can be very useful to construct a dataframe containing all the spatial predictors. That’s the strategy that C & F follow:\n\nPCs &lt;- scores(pca, choices=c(1:3), display=\"sites\", scaling=0)\nPopStruct &lt;- data.frame(Population = Neutral[,1], PCs)\ncolnames(PopStruct) &lt;- c(\"Population\", \"PC1\", \"PC2\", \"PC3\")\n\n#check the object \nPopStruct[1:5,]\n\n## Table gathering all variables inlcuding environment\nVariables &lt;- data.frame(Coordinates, PopStruct[,-1], Env) #original scripts include traits - we are ignoring those for now\n\nVariables[1:5,]\n\nNote that PC eigenvectors will already be scaled. You can test this using sum(PopStruct$PC1). There might be a small value due to rounding error but it will be very small."
  },
  {
    "objectID": "RDA.html#building-a-full-rda-model-for-environmental-variables-with-forward-selection",
    "href": "RDA.html#building-a-full-rda-model-for-environmental-variables-with-forward-selection",
    "title": "Intro to RDA as a flexible tool",
    "section": "Building a full RDA model for environmental variables with forward selection",
    "text": "Building a full RDA model for environmental variables with forward selection\n\nForward selection starts from a “null” model where the response is explained only by an intercept. Variables are then added to the model one by one to try to reach the amount of variance explained by a “full” model (i.e., model including all the explanatory variables), while limiting the amount of redundancy among included variables.\n\nWhether forward selection is the best approach or not is debatable, but it is the most common procedure for dealing with multiple variables. To do this, you first build the intercept only model and then define a full model.\n\n## Null model\nRDA0 &lt;- rda(AllFreq ~ 1,  Variables) \n\n## Full model\nRDAfull &lt;- rda(AllFreq ~ AHM + bFFP + CMD + DD_0 + DD_18 + DD18 + DD5 + eFFP + EMT + Eref + EXT + FFP + MAP + MAR + MAT + MCMT + MSP + MWMT + NFFD + PAS + PPT_sm + PPT_wt + RH + SHM + Tave_sm + Tave_wt + TD, Variables)\n\nExamine the structure of RDA0 by just typing RDA0 and also summary(RDA0). There is a lot of information but the structure is essentially a PCA, since we did not define any explanatory variables. As before, the “Species scores” are your column variables, which are loci in this case. The “Site scores” are row variables or populations.\nOnce you have looked at RDA0, take a look at RDAfull. Now you will see constrained inertia that represents the variance explained by your predictor variables. (Notice that most variance remains unconstrained, this is quite common). Remember that the predictor variables have now been ordinated as RDA eigenvectors where each RDA axis is orthogonal to the others. The eigenvalues represent how much variance in response variables (allele frequencies) is predicted by that eigenvector, e.g., RDA1 predicts 29.4/578 percent of the variance in allele frequencies.\nThe last table in summary(RDAfull) shows how the different environmental variables load onto each RDA axis.\nTo make a quick plot of your RDA, now use ordiplot. This will make a biplot that combines your populations (points) and predictor variables (arrows).\n\nordiplot(RDAfull)\n\nThe vegan package is very well documented and it is worth spending time learning some of the options if you are going to be using ordination in your toolbox of analyses.\n\nTo conduct the selection procedure we used the ordiR2step function of the package vegan and the following stopping criteria: variable significance of p &lt; 0.01 using 1000 permutations, and the adjusted R2 of the global model.\n\nBecause this command will take a long time to run, I suggest that you start it and watch what it is doing, but I have saved the output mod for you to import, so you can stop the process to speed things up.\nInterrupt the processing for the sake of time and load the output of the full ordiR2step:\n\n# load the output\nload(\"./home/data/mod.Rdata\")\n\nAs before, examine the mod object in detail. How much variance does RDA1 explain? Is RDA1 dominated by a single environmental variable or spread among variables?\nmod$anova will give you most of the output shown in Table 1 from C & F. You would just need to do some subtraction to get the R2 for each term - for example, EMT = 0.044517-0.022167 = 0.02235.\n(And you don’t need to report all those decimal places, IMO)\nFrom C & F:\n\nIn total, nine of the 27 bioclimate variables were selected: MAR, EMT, MWMT, CMD, Tave_wt, DD_18, MAP, Eref and PAS.\n\n\nNotes on interpretation and best practices: We remind users that this predictive approach to variable selection optimizes the variance explained, but does not necessarily identify the ecological or mechanistic drivers of genetic variation. Additionally, pairwise predictor correlations can be very high, e.g., among seasonal calculations of temperature or precipitation. While one variable may maximize variance explained, it may be another, correlated variable, potentially even unmeasured, that is the mechanistic driver of variation. The ubiquitous nature of environmental correlation means that it is critical to carefully investigate selected variables but also avoid overinterpretation of variable importance in downstream analyses unless mechanistic data support observed relationships."
  },
  {
    "objectID": "RDA.html#variance-partitioning-of-the-rda",
    "href": "RDA.html#variance-partitioning-of-the-rda",
    "title": "Intro to RDA as a flexible tool",
    "section": "Variance partitioning of the RDA",
    "text": "Variance partitioning of the RDA\n\nVariance partitioning with partial RDA (pRDA) can identify the contribution of different factors to reducing gene flow and triggering genetic divergence among populations. We apply pRDA-based variance partitioning to the lodgepole pine data to decompose the contribution of climate, neutral population structure, and geography in explaining genetic variation. We used three sets of variables: 1) the nine selected bioclimate variables (‘clim’); 2) three proxies of neutral genetic structure (population scores along the first three axes of a genetic PCA conducted on the 3,934 neutral loci; ‘struct’); and 3) population coordinates (longitude and latitude) to characterize geographic variation (‘geog’).\n\n\nFull model\nBuild the full model with population structure, geography, and environmental variables\n\n## Full model\npRDAfull &lt;- rda(AllFreq ~ PC1 + PC2 + PC3 + Longitude + Latitude + MAR + EMT + MWMT + CMD + Tave_wt + DD_18 + MAP + Eref + PAS,  Variables)\n\nRsquareAdj(pRDAfull)\n\nanova(pRDAfull)\n\nThese values and the subsequent models correspond to Table 2. (There might be some minor discrepancies due to data preparation and permutation based tests.) For some reason, in Table 2, R2 rather than adjusted R2 is reported. You should use adjusted R2: it is penalized by the number of predictor variables (somewhat analogous to AIC).\n\n\nClimate model\nThe climate model is the first of a series of conditioned models. This structure estimates the variance of constrained variables, given conditioning on series of other variables. In this instance, the model is exploring the effect of environmental predictors conditioned upon geography and neutral population structure.\nConditioned models are also called partial RDAs. The conditioned variables show up in the regression model following the “|”: Climate model is \\(F \\sim clim | geog + struct)\\)\n\n## Pure climate model\npRDAclim &lt;- rda(AllFreq ~ MAR + EMT + MWMT + CMD + Tave_wt + DD_18 + MAP + Eref + PAS + Condition(Longitude + Latitude + PC1 + PC2 + PC3),  Variables)\n\nRsquareAdj(pRDAclim)\n\n# can skip to save time \n#anova(pRDAclim)\n\nTake a look at pRDAclim and you will see how Inertia is partitioned among various categories. Information from this model is feeding into the second row of Table 2.\n\nConditional = the amount of variance explained by conditional variables and removed\nConstrained = amount of variance uniquely explained by explanatory variables\nUnconstrained = rest of the variance that is unexplained\n\n\n\nPopulation structure model\nSimilarly a partial RDA can be undertaken for population structure…\n\n## Pure neutral population structure model  \npRDAstruct &lt;- rda(AllFreq ~ PC1 + PC2 + PC3 + Condition(Longitude + Latitude + MAR + EMT + MWMT + CMD + Tave_wt + DD_18 + MAP + Eref + PAS),  Variables)\n\nRsquareAdj(pRDAstruct)\n\n#anova(pRDAstruct)\n\n\n\nGeogrpahy\nAnd another pRDA for geography\n\n##Pure geography model \npRDAgeog &lt;- rda(AllFreq ~ Longitude + Latitude + Condition(MAR + EMT + MWMT + CMD + Tave_wt + DD_18 + MAP + Eref + PAS + PC1 + PC2 + PC3),  Variables)\n\nRsquareAdj(pRDAgeog)\n\n#anova(pRDAgeog)\n\n\nTo replicate Table 2 in the manuscript, we extract the following from the above results:\n\nTotal inertia (aka variance)\nConstrained inertia\nProportion of variance explained by constraints\nModel R^2^\nModel p-value\n\n\nFor the “confounded”row, this should be the full model minus the sum of the partial models, for example, the proportion of explainable variance is 1 - (0.27+0.22+0.05). You can dig into this further with the function varpart().\n\nNote: It is interesting to look at the degree of correlation among variables using a correlogram:\n\n\n#explore other options\ncorrplot(cor(Variables[, c(\"PC1\",\"PC2\",\"PC3\",\"Longitude\",\"Latitude\",\"MAR\",\"EMT\",\"MWMT\",\"CMD\",\"Tave_wt\",\"DD_18\",\"MAP\",\"Eref\",\"PAS\")]), type=\"upper\")\n\n\nNotes on interpretation and best practices: In this case, the largest proportion of genetic variance could not be uniquely attributed to any of the three sets of predictors, a common occurrence given the ubiquitous nature of spatial autocorrelation in environmental and genetic data sets. This confounded effect reflects a high degree of collinearity among explanatory variables. This is critical information given that most landscape genomic studies look for correlation between climatic and genetic variation (i.e., GEA) and either assume no collinearity or, on the contrary, totally remove this commonly explained variation. In the first case, GEA detections could potentially be subject to high false positive rates, while in the latter case detections might show high false negative rates. Selecting an appropriate approach to account for demographic history and geographic distance is of major importance when searching for selection in the genome. Variance partitioning can be a useful step to explore the (statistical) association among available descriptors, to better understand the covariation of environmental and genetic gradients, and to determine how much overall genetic variation is shaped by environmental, geographic, and demographic factors before conducting further landscape genomics study.\n\nAnother way to look for correlations is to use variance inflation factors, where the square root of the value &gt; 2 indicates multicollinearity.\n\nsqrt(vif.cca(pRDAfull))\n\n(Not really a good sign!)"
  },
  {
    "objectID": "RDA.html#the-amazing-flexibility-of-rda",
    "href": "RDA.html#the-amazing-flexibility-of-rda",
    "title": "Intro to RDA as a flexible tool",
    "section": "The amazing flexibility of RDA",
    "text": "The amazing flexibility of RDA\n\nPopulations or individuals\nThe above tutorial was conducted on populations, but if your sampling is at the individual level, you can use RDA for individual based analyses. Note that this assumes that each individual has a unique set of predictor variables. You would center and scale your genotype data as with population level analyses.\n\n\nUsing link based predictors\nIn a standard analyses as conducted in C&F’s tutorial, the predictive variables have site or node based attributes - that is a one-to-one relationship between populations (or individuals) and predictors. Sometimes, however, you might be focused on link attributes such as the geographic distance between sites.\nIf this is the case, you should organise your distances as a square matrix with dimensions equal to the number of populations. Principal coordinates analysis (PCoA) = metric multidimensional scaling can then be used to undertake ordination based on these pairwise distances. You will then need to decide how many axis of the PCoA to use as your predictors in the RDA. For example, say you wanted to get geographic distances based on projected locations. If this is the case, PCoA1 and PCoA2 are likely to be sufficient to capture most of the variation. Note that a PCoA on Euclidean distances is the same as a PCA.\nThe procedure of incorporating PCoA axes from a distance matrix in RDA is sometimes called distance-based redundancy analyses, dbRDA."
  },
  {
    "objectID": "RDA.html#moran-eigenvector-maps",
    "href": "RDA.html#moran-eigenvector-maps",
    "title": "Intro to RDA as a flexible tool",
    "section": "Moran Eigenvector Maps",
    "text": "Moran Eigenvector Maps\nAs you are aware, spatial autocorrelation structures are common in spatial data and can arise through many processes. In the tutorial from C&F, spatial autocorrelation is dealt with (sort of) by using latitude and longitude as covariates. A more sophisticated way of allowing for spatial autocorrelation (and testing for it) is to use Moran Eigenvector Maps (MEMs). This approach derives orthogonal vectors of possible spatial autocorrelation structures. These can be included as predictors in an RDA (or other analyses).\nSome functions return both positive and negative MEMs. The total number of MEMs are equal to the number of popultions with the first half being positive - typically we only focus on the positive MEMs. The MEMs with lower numbers (1, 2, 3 etc) describe larger spatial patterns and higher numbers are more particulate.\nThe code below draws upon adespatial and spdep that were developed by authors involved in the key theory related to MEMs. These packages, however, are a bit out of date and so in the future you will want to see if there are updates.\nThe first bit of code shows MEMs for a simple spatial grid so you can build up your inference. The second bit of code shows how you would find MEMs for the irregular lodgepole pine data.\n\nlibrary(ade4)\nlibrary(adespatial)\nlibrary(spdep)\nlibrary(adegraphics)\n\n\n# Demonstration of MEMs on a grid\nxygrid &lt;- expand.grid(x = 1:10, y = 1:8)\nplot(xygrid)\nxygrid.mem&lt;-dbmem(xygrid,store.listw = TRUE)\nplot(xygrid.mem, SpORcoords = xygrid)\n\n\n# Looking at MEMS for lodgepole pine data\npine.mem&lt;-dbmem(Coordinates[,c(2,3)], MEM.autocor = \"positive\", store.listw = TRUE)\nplot(pine.mem, SpORcoords = Coordinates[,c(2,3)])\n\nYou could play with using the first few MEMs in modified RDAs of the pine data. Remove longitude and latitude if you do this.\nIf you plan to use MEMs in your own research, you will want to investigate much further. Right now, this code demonstrate how you can make them so you have a basic understanding of what they are when you read about MEMs in paper. A good place to start would be by following the adespatial tutorial."
  },
  {
    "objectID": "sims_demo.html#running-fastsimcoal2",
    "href": "sims_demo.html#running-fastsimcoal2",
    "title": "Sims & demograph analyses",
    "section": "Running fastsimcoal2",
    "text": "Running fastsimcoal2\nOnce we have all input files ready, it is time to run fastsimcoal2. In addition to the input files, we need to specify how many simulations and iterations fastsimcoal2 should perform, when to stop and how many threads (i.e. CPUs) can be used in parallel.\nLet’s run fastsimcoal2 with our model of two populations. First we make a fastsimcoal2 directory and within that a directory, an additional one for our model of early_geneflow:\ncd ~\nmkdir fastsimcoal2\ncd fastsimcoal2\nmkdir early_geneflow\nNext, we will move inside this directory and copy over the files we need\ncd ~/fastsimcoal2/early_geneflow\ncp /resources/riverlandsea/exercise_data/fastsimcoal2/early_geneflow/* .\nThis should mean we have our observed SFS, our template file and our estimation file. We are now ready to run fastsimcoal2 - we will set a PREFIX variable to make our command here a bit easier to write. This will help downstream too!\nPREFIX=\"early_geneflow\"\nfastsimcoal2 -t ${PREFIX}.tpl -e ${PREFIX}.est -m -0 -C 10 -n 10000 -L 40 -s 0 -M\nThis command runs fastsimcoal2 using a MAF (-m) while ignoring monomorphic sites (-0) and SFS entries with less than 10 SNPs (-C). This means that entries with less than 10 SNPs are pooled together. This option is useful when there are many entries in the observed SFS with few SNPs and with a limited number of SNPS to avoid overfitting.\nfastsimcoal2 will also perform (-n) 10,000 coalescent simulations to approximate the expected SFS in each cycle and will run (-L) 40 optimization (ECM) cycles to estimate the parameters. The number of ECM cycles should be at least 20, better between 50 and 100. The number of coalescent simulations should ideally be something between 200,000 and 1,000,000 but to make it faster, we are now only running 10,000 simulations. We also specify (-M) that we want to perform parameter estimation. With -s 0, we can tell fastsimcoal2 to output SNPs.\nOnce fastsimcoal2 is finished, we can have a look at the output files. It produced a folder called ${PREFIX} which contains a number of new files. The most relevant files are the following:\n\n${PREFIX}.bestlhoods: a file with the Maximum likelihood estimates for each parameter specified “output” in the est file and the model likelihoods.\n${PREFIX}._jointMAFpop1_0.txt: a file with the expected SFS obtained with the parameters that maximized the likelihood during optimization. This is needed to visually check the fit of the expected SFS to the observed SFS. This file has the same suffix as the observed SFS provided.\n${PREFIX}.simparam: a file with an example of the settings to run the simulations. This is useful to check when you have errors. Many times errors in specification of models can be detected in this file.\n${PREFIX}_maxL.par: The model specification file with the best parameter estimates. It is basically the tpl file with the keywords replaced by estimated values. This file is useful if you want to simulate data under the best model using Arlequin.\n\nNote, the bestlhoods file contains two different likelihoods: MaxObsLhood is the maximum possible value for the likelihood if there was a perfect fit of the expected to the observed SFS, i.e. if the expected SFS was the relative observed SFS. MaxEstLhood is the maximum likelihood estimated according to the model parameters. It is obtained by using the observed SFS as the expected SFS when computing the likelihood, i.e., returning the value of the likelihood if there was a perfect fit between the expected and observed SFS.\nThe better the fit, the smaller the difference between MaxObsLhood and MaxEstLhood.\n\nFinding the best parameter estimates\nfastsimcoal2 should not just be run once because it might not find the global optimum of the best combination of parameter estimates right away. It is better to run it 100 times or more. Of these runs, we then go on to select the one with the highest likelihood which is the run with the best fitting parameter estimates for this model.\nDue to time constraints, we will only run this model 5 times and we will do so within a for loop. Note, that here we have added the flag -q for “quiet” which reduces the amount of information fastsimcoal2 writes to stdout. Pay attention the cd commands here as they ensure that the analyses are done in the correct directory.\n for i in {1..5}\n do\n   mkdir run$i\n   cp ${PREFIX}.tpl ${PREFIX}.est ${PREFIX}_jointMAFpop1_0.obs run$i\"/\"\n   cd run$i\n   fastsimcoal2 -t ${PREFIX}.tpl -e ${PREFIX}.est -m -0 -C 10 -n 10000 -L 40 -s0 -M -q\n   cd ..\n done\nTo find the best run, i.e. the run with the highest likelihood, or better the smallest difference between the maximum possible likelihood (MaxObsLhood) and the obtained likelihood (MaxEstLhood), we can check the .bestlhoods files.\ncat run{1..5}/${PREFIX}/${PREFIX}.bestlhoods | grep -v MaxObsLhood | awk '{print NR,$8}' | sort -k 2\nNote that NR in awk prints out the line number which here corresponds to the run number. $8 is the MaxEstLhood column and thus the likelihood we want to compare across different runs.\n[Joana Meier](https://www.sanger.ac.uk/person/meier-joana/ has written a script for you that automatically extracts the files of the best run and copies them into a new folder which it calls bestrun. A copy of that script is available in the course resources directory so we will copy it to our run folder directory and run it like so:\nJust run it in the directory where all the folders run are located and run it:\ncd ~/fastsimcoal2/early_geneflow\ncp /resources/riverlandsea/exercise_data/fastsimcoal2/fsc-selectbestrun.sh\n./fsc-selectbestrun.sh\nNow modify the $PREFIX.tpl and $PREFIX.est files to specify different models and also rename the SFS to ${PREFIX}_jointDAFpop1_0.txt. Then run fastsimcoal2for all models to see which one shows the best fit to the observed SFS.\n\n\n\nClick here to see a possible solution.\n\n\nEarly Geneflow (this is the model expalined in the example, gene flow right after the split and then no gene flow anymore, e.g. speciation with gene flow and then no gene flow anymore as reproductive isolation becomes strong):  tpl  est   No geneflow:  tpl  est   Recent geneflow (no gene flow intially after the split but gene flow in recent times, e.g. secondary contact scenario)  tpl  est   Different gene flow matrices (higher or lower gene flow right after the split than recently, e.g. initially higher gene flow then lower gene flow as reproductive isolation accumulates):  tpl  est   Constant gene flow (same gene flow strengths since the split until now):  tpl  est\n\n\n\n\nModel comparison with AIC\nIn order to find the best model, the likelihoods of the best run of each model should be compared. Comparing raw likelihoods is problematic, because a model with more parameters will always tend to result in a better fit to the data. Therefore, the Akaike information criterium or AIC is typically calculated to determine if the models differ in their likelihoods accounting for the number of parameters in each model. To perform, this, we can use a script that is mostly based on R code by Vitor Sousa. We will move into our bestrun directory and run this script\ncd bestrun/\ncp /resources/riverlandsea/exercise_data/fastsimcoal2/calculateAIC.sh .\n./calculateAIC.sh early_geneflow\nThis script generates a file ${PREFIX}.AIC which contains the delta likelihood and the AIC value for that run.\n\n\nVisualize the model fit\nTo visualize the fit of the simulated SFS to the data, we can use an R script that David Marques wrote - SFStools.r - which you can download here.\nTo visualize the model with the best parameter estimates, we can use one of Joana Meier’s R scripts - plotModel.r. There are also other options here. However for the ease of this practical, both are available in the resources directory. We will copy them over and then run them.\ncp /resources/riverlandsea/exercise_data/fastsimcoal2/*.r .\nSFStools.r -t print2D -i early_geneflow\nplotModel.r -p early_geneflow -l NyerMak,PundMak\nNow, we will download the PDFs genertated and take a look at them.\n\n\nModel comparison with Likelihood distributions\nOne drawback of the composite likelihoods in model tests based on AIC is that it can overestimate the support for the most likely model if the SNPs are not independent (here they are not LD-pruned). Another way to infer if the models are really different and do not just differ because of stochasticity in the likelihood approximation, is to get likelihood distributions for each model. This is done by running each model with the best parameter values multple times (ideally about 100 times). The likelihoods will differ because fastsimcoal2 does not compute the likelihood but rather approximates it with simulations. If the ranges of likelihoods of two models overlap, it means that they do not differ significantly, i.e. provide an equally good fit to the observed data.\nLet’s recompute the likelihood for the best run for the early_geneflow model.\n\nPREFIX=\"early_geneflow\"\ncd ~/fastsimcoal/$PREFIX/bestrun\n\n# create temporary obs file with name _maxL_MSFS.obs\ncp ${PREFIX}_jointMAFpop1_0.obs ${PREFIX}_maxL_jointMAFpop1_0.obs\n\n# Run fastsimcoal 20 times (in reality better 100 times) to get the likelihood of the observed SFS under the best parameter values with 1 mio simulated SFS.\nfor i in {1..20}\ndo\n fastsimcoal2 -i ${PREFIX}_maxL.par -n1000000 -m -q -0\n # Fastsimcoal will generate a new folder called ${model}_maxL and write files in there\n\n # collect the lhood values (Note that &gt;&gt; appends to the file, whereas &gt; would overwrite it)\n sed -n '2,3p' ${PREFIX}_maxL/${PREFIX}_maxL.lhoods  &gt;&gt; ${PREFIX}.lhoods\n\n # delete the folder with results\n rm -r ${PREFIX}_maxL/\ndone\n\nWe would now repeat this for different models: ongoing gene flow, a model without gene flow, a model of secondary contact (recent gene flow) and a model with different amounts of gene flow in the past and in recent times.\nDue to time constraints, we will give you the results of these models. They are in the same format as the folder we generated for the model with early gene flow. Load them into your own directory. Note, the -r flag stands for “recursive” and allows to also copy directories and their contents.\ncd ~/fastsimcoal2/\ncp -r /resources/riverlandsea/exercise_data/fastsimcoal2/extramodels\nNow, let’s access the R Studio sderver and plot the likelihoods.\n\n\n# Read in the likelihoods\nearly_geneflow&lt;-scan(\"early_geneflow.lhoods\")\nongoing_geneflow&lt;-scan(\"ongoing_geneflow.lhoods\")\ndiff_geneflow&lt;-scan(\"diff_geneflow.lhoods\")\nrecent_geneflow&lt;-scan(\"recent_geneflow.lhoods\")\nno_geneflow&lt;-scan(\"no_geneflow.lhoods\")\n\n# Plot the likelihoods\n\npar(mfrow=c(1,1))\nboxplot(range = 0,diff_geneflow,recent_geneflow,early_geneflow,ongoing_geneflow,\n        no_geneflow, ylab=\"Likelihood\",xaxt=\"n\")\naxis(side=1,at=1:5, labels=c(\"early+recent\",\"recent\",\"early\",\"constant\",\"no\"))\nSimilarly, we should compare the AIC values and see if AIC suggests that the second-best model is significantly less good than the best model. Given that we already used the calculateAIC.r script to compute AIC values, this can easily be done.\nfor i in */bestrun/*AIC\ndo\necho -e `basename $i`\"\\t\"`tail -n $i` &gt;&gt; allmodels.AIC\ndone\nAnd we’re done for this tutorial! It is worth noting that linkage among SNPs can actually distort the AIC and likelihood calculations. As a result it is best practice to perform block-bootstrapping to account for this. We don’t have time to implement that here but you can refer to the original version of this tutorial which does have a guide for how to achieve this."
  },
  {
    "objectID": "basicR.html",
    "href": "basicR.html",
    "title": "Basic R",
    "section": "",
    "text": "If you are new to R, please attempt the following tutorials on your own. If you are experienced in R, skim through the tutorials and make sure that all the topics are familiar to you.\n\nRavinet’s introduction to R\nGoing further with R\n\nThrough this course, most of the examples you are likely to encounter will predominately use base R. However, learning Tidyverse syntax will make your life easier in the long run, especially if you are going to be manipulating spatial data."
  },
  {
    "objectID": "land-river-sea.html",
    "href": "land-river-sea.html",
    "title": "Land, river, & seascape genomics",
    "section": "",
    "text": "(landscape = any habitat)\n\n“At the heart of spatial and space–time analysis of population genetics is the connection between observed spatial patterns and the space–time processes that generate them.” - Epperson 2003\n\n\n“the interaction between landscape features and microevolutionary processes, such as gene ﬂow, genetic drift and selection.” - Manel et al 2003\n\n\nLandscape genetics tests the model that \\(G \\sim f(E)\\) - Dyer 2015, Molecular Ecology\n\n\n\nNo, just swap “genetics” for “genomics” - Balkenhol et al 2016\nYes - “Whereas landscape genetics studies primarily focus on testing the effects of landscape variables on gene ﬂow and genetic population structure, landscape genomics studies focus on detecting candidate genes under selection that indicate possible local adaptation.” - Storfer et al 2018\n\n\n\nComparing landscape genetics and genomics - Storfer et al 2018\n\n\nIn this course, we will focus on a few topics in landscape genomics aiming to give you a solid foundation in the field. We will not be comprehensive but will try to point out important topics when we encounter them. There is a stronger emphasis on population genomics and various landscapes (especially marine) than might be found in other landscape genomic courses.\nWhat are we covering and why?\n\nMaking maps and using spatial data\nDescribing genetic variation and genetic structuring\nRDA as a flexible tool\nSimulations and demographic analyses\nResistance surfaces\nProjecting into the future with generalised dissimilarity modelling, gradient forests\nBiophysical models of dispersal\nMore GEAs and genomic offsets\n(Time permitting) Landscape genomics and genetic architectures\n\nSome important topics we will not cover very much/at all\n\nSampling design\nTests of selection"
  },
  {
    "objectID": "land-river-sea.html#is-landscape-genomics-fundamentally-different-from-landscape-genetics",
    "href": "land-river-sea.html#is-landscape-genomics-fundamentally-different-from-landscape-genetics",
    "title": "Land, river, & seascape genomics",
    "section": "",
    "text": "No, just swap “genetics” for “genomics” - Balkenhol et al 2016\nYes - “Whereas landscape genetics studies primarily focus on testing the effects of landscape variables on gene ﬂow and genetic population structure, landscape genomics studies focus on detecting candidate genes under selection that indicate possible local adaptation.” - Storfer et al 2018\n\n\n\nComparing landscape genetics and genomics - Storfer et al 2018\n\n\nIn this course, we will focus on a few topics in landscape genomics aiming to give you a solid foundation in the field. We will not be comprehensive but will try to point out important topics when we encounter them. There is a stronger emphasis on population genomics and various landscapes (especially marine) than might be found in other landscape genomic courses.\nWhat are we covering and why?\n\nMaking maps and using spatial data\nDescribing genetic variation and genetic structuring\nRDA as a flexible tool\nSimulations and demographic analyses\nResistance surfaces\nProjecting into the future with generalised dissimilarity modelling, gradient forests\nBiophysical models of dispersal\nMore GEAs and genomic offsets\n(Time permitting) Landscape genomics and genetic architectures\n\nSome important topics we will not cover very much/at all\n\nSampling design\nTests of selection"
  },
  {
    "objectID": "land-river-sea.html#spatial-variable-attributes",
    "href": "land-river-sea.html#spatial-variable-attributes",
    "title": "Land, river, & seascape genomics",
    "section": "Spatial variable attributes",
    "text": "Spatial variable attributes\n(that often violate statistical assumptions)\n\n\n\nAttributes of spatial variables - Riginos et al. 2016\n\n\nOther factors to consider -\n\nWhat is the grain size of your spatial variables?\nAre spatial variables site specific or gridded (remote sensing)"
  },
  {
    "objectID": "land-river-sea.html#relationship-of-lg-to-landscape-ecology",
    "href": "land-river-sea.html#relationship-of-lg-to-landscape-ecology",
    "title": "Land, river, & seascape genomics",
    "section": "Relationship of LG to landscape ecology",
    "text": "Relationship of LG to landscape ecology\nMany of the methods used in landscape genetics/genomics have their origins in spatial (landscape) ecology.\n\nMethods papers and supporting documentation for analyses are likely to have species as the unit of inference - usually you can replace “species” with “loci”\nAlso, get used to thinking about genetic diversity in terms of alpha and beta diversity\nMethodological inspirations for landscape genomics often come from landscape genetics, especially for describing spatial structure\nTools borrowed from landscape ecology help move between different types of data and analyses\n\nAlpha and beta diversity:\n\n\n\n“7: Alpha, Beta, and Gamma Diversity.” Biology LibreTexts, Libretexts, 10 Sept. 2021.\n\n\nStatistical models for representing relationships among and between locations:\n\n\n\nStatistical models - Wagner & Fortin 2016"
  },
  {
    "objectID": "land-river-sea.html#geas-genotype-by-environment-associations",
    "href": "land-river-sea.html#geas-genotype-by-environment-associations",
    "title": "Land, river, & seascape genomics",
    "section": "GEAs: Genotype-by-environment associations",
    "text": "GEAs: Genotype-by-environment associations\n( = environmental associations)\n\nGenome-wide: related to demographic history, ecological speciation/diversification, isolation by environment\n\n\n\n\nProcesses leading to IBE - Wang & Bradburd 2014\n\n\n\n\n\nIBE signals - Wang & Bradburd 2014\n\n\nTutorial on RDAs, GDM, and GF mostly sit in this category.\n\nFinding loci contribute to heritable genetic variation of selected traits\n\n\n\n\nRellstab et al 2015 (Image modified from Sork et al 2013)\n\n\nThere is a huge literature on the topic of finding candidate loci for environmental selection that we cannot cover in one week. Population genetic tests of selection such as outlier tests or genomic scans are frequently used. There are also tests of selection that specifically look for associations of individual loci to environmental attributes - often called GEA, genotype-environment association or EAA, environment association analysis - this will be more of our focus given that we are studying landscape genomics. We will come back to this topic on Friday. (Rellstab et al. 2015 and Storfer et al 2018 have good reviews of the various methods if you are looking for further reading on this topic.)"
  },
  {
    "objectID": "GDM.html",
    "href": "GDM.html",
    "title": "Future projections with GDM & GFs",
    "section": "",
    "text": "Instructor: Riginos"
  },
  {
    "objectID": "GDM.html#gdm",
    "href": "GDM.html#gdm",
    "title": "Future projections with GDM & GFs",
    "section": "GDM",
    "text": "GDM\n\nTheory/Background for GDM\n\nManaging non linearity\nGDM is non linear extension of matrix regression that uses dissimilarities in both predictor and response variables:\n\nBasic linear model: \\(d_{ij} = a_0 + \\sum_{p=1}^na_p|x_{pi}-x_{pj}|\\)\n\nModified to account for two aspects of non linearity:\n\nBounded compositional dissimilarity: \\(d_{ij} \\sim (0,1)\\)\nVariable rate of turnover\n\n\n\n\nTwo types of non linearity - Ferrier et al 2007\n\n\nSolution for #1, use a generalized linear model that defines relationship between predictor (\\(\\eta\\)) and response (\\(\\mu\\))\n\nLink function: \\(\\mu = 1 - e^{\\eta}\\)\nBinomial variance: \\(V(\\mu) = \\frac{\\mu(\\mu-1)}{s_i+s_j}\\)\n\nSolution for #2: fit nonlinear functions to the environmental variables, not their distances\n\nGLM equation is now changed to include functions for x\n\n\\(\\eta = a_0 + \\sum_{p=1}^n|f_p(x_{pi})-f_p(x_{pj})|\\)\n\nan I-spline basis function is used as a function\n\n\\(f_p(x_p)= \\sum_{k=1}^{m_p}a _{pk}I_{pk}(x_p)\\) (k splines per predictor)\n\nSo, GLM becomes: \\(\\eta = a_0 + \\sum_{p=1}^n\\sum_{k=1}^{m_p}a_{pk}|I_{pk}(x_{pi})-I_{pk}(x_{pj})|\\)\n\n\n\nFitting a GDM model\n\ncompute \\(d_{ij}\\) between all sites (n x n matrix)\nderive a set of \\(m_p\\) I-spline basis functions for each environmental variable and calculate value (\\(I_{pk}(x_p)\\))for each site\nCalculate \\(\\Delta I_{pk}\\) for each pair of sites\nFor geographic and other distances, derive I-spline basis functions directly\nUse maximum likelihood to fit coefficients\nContribution of each predictor evaluated by comparing deviance of model with and without the factor\n\n\n\n\nAssembling a GDM - Mokany et al 2022\n\n\nExamining the I-splines\nUses of GDM"
  },
  {
    "objectID": "GDM.html#gdm-applications-species-diversity",
    "href": "GDM.html#gdm-applications-species-diversity",
    "title": "Future projections with GDM & GFs",
    "section": "GDM applications (species diversity)",
    "text": "GDM applications (species diversity)\n\n\n\nGDM usage examples for present climate\n\n\n\n\n\nGDM usage examples for future climate"
  },
  {
    "objectID": "GDM.html#advantages-and-limitations-of-gdm",
    "href": "GDM.html#advantages-and-limitations-of-gdm",
    "title": "Future projections with GDM & GFs",
    "section": "Advantages and limitations of GDM",
    "text": "Advantages and limitations of GDM\n\nPositives\n\nVery flexible on data types\nComputation (for genetic analyses) does not scale with number of loci\nDoes not assume linearity\nCan yield predictions for gridded landscapes\n\n\n\nDrawbacks\n\nPredictor distances are symmetric\nPredictions in a large gridded landscape: computationally challenging (grid cell number choose 2 combinations)\nInteractions between predictors are not modeled\nNon independence of sites not accounted for if all sites used (Mokany et al. 2022)\nAlternative link functions might be more appropriate"
  },
  {
    "objectID": "GDM.html#theory",
    "href": "GDM.html#theory",
    "title": "Future projections with GDM & GFs",
    "section": "Theory",
    "text": "Theory\n\nRandom forests\n\nCreates an ensemble of trees per species, these trees are split into partitions\nObservations (sites for species, populations for genetics) are picked at random for each regression tree\nFor each node in the regression tree, predictor variables are selected at random and evaluated\nSites are split by a predictor value, s\nSplits are chosen to create homogenous groups (measured by the sum of squared deviations about the group mean, called the impurity); the importance of each split is the reduction in impurity introduced by the split\nSplitting occurs recursively until the tips are reached\nRandom forest = ensemble of trees where each trees is a bootstrap partition\nCross validation using “in bag” and “out of the bag” comparisons\n\nConfused? Me too! Let’s watch this video to get a better understanding…\n\n\n\n\nGradient forests\nCombines ensembles of random forests to summarize importance of predictors and compositional turnover rates by predictor values.\n\n\n\nHow gradient forests work - Ellis et al 2012"
  },
  {
    "objectID": "GDM.html#gf-applications-species-diversity",
    "href": "GDM.html#gf-applications-species-diversity",
    "title": "Future projections with GDM & GFs",
    "section": "GF applications (species diversity)",
    "text": "GF applications (species diversity)\nExample - outcomes for species abundance for species on the Great Barrier Reef\n\n\n\nGF outputs\n\n\n\n\n\nMore GF outputs\n\n\nOther applications\n\nPredicting biological turnover from environmental variables\nGap analyses of surveys\nIdentifying environmental thresholds to push community into a different state"
  },
  {
    "objectID": "GDM.html#advantages-and-limitations-of-gf",
    "href": "GDM.html#advantages-and-limitations-of-gf",
    "title": "Future projections with GDM & GFs",
    "section": "Advantages and limitations of GF",
    "text": "Advantages and limitations of GF\n\nPositives\n\nSummarizes complex relationships with high predictive power - no variable transformation required\nSpecies can be sampled in different ways and combined\nCompositional dissimilarity is not bounded at 1\nCorrelated predictors should not affect results within the training region (but could if model is applied to new regions)\n\n\n\nNegatives\n\nDoes not explicitly deal with spatial location (positions can be added as variables)\nSmall scale autocorrelation could cause problems - sample at distances larger than local SA"
  },
  {
    "objectID": "GDM.html#the-data-set",
    "href": "GDM.html#the-data-set",
    "title": "Future projections with GDM & GFs",
    "section": "The data set",
    "text": "The data set\n\nReference SNPs\n\n412 SNPs = genomically random\n31 populations\n474 individuals\n\nCandidate loci\n\n335 SNPS from flowering genes\n443 individuals from 31 populations\n\nSNPs from specific candidate loci\n\nprevious outlier analyses identified GIGANTEA-5 (GI5), FRIGIDA (FRI) and LEAFY (LFY)\n\nEnvironmental variables: 6\nSpatial structure (population history) accounted for by using geographic distance for GDM and MEMs for GF\nGDM - response variables are pairwise Fst\nGF - response variables are allele frequencies"
  },
  {
    "objectID": "GDM.html#results",
    "href": "GDM.html#results",
    "title": "Future projections with GDM & GFs",
    "section": "Results",
    "text": "Results\n\n\n\nGDM I-splines: Fitzpatrick & Keller 2015\n\n\nSee Figure 2 in the original paper for similar GF results as above.\n\n\n\nTurnover by SNP in response to summer temperature - Fitzpatrick & Keller 2015\n\n\n\n\n\nPredicted spatial variation - Fitzpatrick & Keller 2015"
  },
  {
    "objectID": "GDM.html#notes-developed-from",
    "href": "GDM.html#notes-developed-from",
    "title": "Future projections with GDM & GFs",
    "section": "Notes developed from:",
    "text": "Notes developed from:\n\n\nEllis, N., Smith, S. J., & Pitcher, C. R. (2012). Gradient forests: calculating importance gradients on physical predictors. _Ecology, 93_(1), 156-168.\nFerrier, S., Manion, G., Elith, J., & Richardson, K. (2007). Using generalized dissimilarity modelling to analyse and predict patterns of beta diversity in regional biodiversity assessment. _Diversity and Distributions, 13_(3), 252-264.\nFitzpatrick, M. C., & Keller, S. R. (2015). Ecological genomics meets community-level modelling of biodiversity: mapping the genomic landscape of current and future environmental adaptation. _Ecol Lett, 18_(1), 1-16.\nMokany, K., Ware, C., Woolley, S. N. C., Ferrier, S., Fitzpatrick, Matthew C., & Bahn, V. (2022). A working guide to harnessing generalized dissimilarity modelling for biodiversity analysis and conservation assessment. _Global Ecology and Biogeography, 31_(4), 802-821."
  },
  {
    "objectID": "GDM.html#overview",
    "href": "GDM.html#overview",
    "title": "Future projections with GDM & GFs",
    "section": "Overview",
    "text": "Overview\nThis tutorial will provide the briefest introduction to GDMs and GF’s and their usage in landscape genomics.\nThese methods are included because the represent different ways of approaching landscape data and are often encountered in genomic prediction studies.\nThe scripts support the analyses presented in Fitzpatrick and Keller 2015 on balsam poplar and are based on the scripts and data found on Data Dryad.\nUnfortunately the authors did not make their spatial data layers available (likely due to large file sizes) and therefore we cannot recapitulate their landscape projections to look at genomic offsets. We will do this later based on an RDA method.\nAs we have encountered before, support for the packages GDM and gradientForest might not be fully up to date with developments in R spatial data handling.\nAll data from: Fitzpatrick, M. C., & Keller, S. R. (2015). Ecological genomics meets community-level modelling of biodiversity: mapping the genomic landscape of current and future environmental adaptation. Ecol Lett, 18(1), 1-16.\n\n#install.packages(\"gradientForest\", repos=\"http://R-Forge.R-project.org\")\nlibrary(gdm) #notice the warnings, we can talk about this\nlibrary(gradientForest)\nlibrary(raster)"
  },
  {
    "objectID": "GDM.html#gdm-1",
    "href": "GDM.html#gdm-1",
    "title": "Future projections with GDM & GFs",
    "section": "GDM",
    "text": "GDM\nRemember that GDM is based on distances between sites. If you examine the gdmData file you will see that each row contains information regarding the relationship between a pair of sites.\n\nGenetic data - Representing the genetic response variables are FST values for various sets of data (reference loci, candidate, GI5, etc.) These Fst values have been scaled and centered.\nCoordinates - The locations of each population pair are included as x and y coordinates.\nEnvironmental distances - expressed as \\(\\Delta I_{pk}\\) values - these have been calculated already by running the function formatsitepair(). If you were preparing your own data, you would need to run this function to fit the splines.\n\n\nFitting and examining the GDM model\nWe will focus on the reference and GIGANTEA-5 (GI5) datasets. To fit the models, individual dataframes need to be constructed.\nThe datafile should be preloaded, otherwise download from here.\n\n# import GDM ready table\ngdmData &lt;- read.csv(\"./data/poplarFst.ENV.data.4.GDM.csv\")\n\n\n# build individual SNP datasets\nSNPs_ref &lt;- gdmData[,c(1,6:24)] # reference\nGI5 &lt;- gdmData[,c(3,6:24)] # GIGANTEA-5 (GI5)\n\n\n# fit and plot GDM for reference SNPs\ngdmRef &lt;- gdm(SNPs_ref, geo=TRUE) #gives warning but works\ngdmRef$explained # From F&K2015: \"GDM explained more than 63% of the deviance in turnover in genetic composition of reference\"\n\nplot(gdmRef)\nrefSplines &lt;- isplineExtract(gdmRef) # extract spline data for custom plotting\n\n# fit and plot GDM for GI5 SNPs\ngdmGI5 &lt;- gdm(GI5, geo=TRUE) #ignore warning\ngdmGI5$explained\nplot(gdmGI5)\n\nYou will recognize some of the plots from Figure 3. Notice how variable the spline functions can be."
  },
  {
    "objectID": "GDM.html#gf",
    "href": "GDM.html#gf",
    "title": "Future projections with GDM & GFs",
    "section": "GF",
    "text": "GF\nIn contrast to GDM, GF is site based. Therefore each row in the dataframe corresponds to a site (population).\n\nCoordinates - The locations of each population are included as x and y coordinates.\nEnvironmental values - Appear to be raw values.\nMEMS - are included as additional spatial variables.\nGenetic data - Are allele frequencies. (Columns 14-373 are reference loci =360 loci, does not match the paper!)\n\n\nFitting and examining the GF model\nAs before, we focus on the reference and GIGANTEA-5 (GI5) datasets. And make individual dataframes to feed into the analyses.\nThe datafile should be preloaded, otherwise download from here.\n\ngfData &lt;- read.csv(\"./data/poplarSNP.ENV.data.4.GF.csv\")\n\nenvGF &lt;- gfData[,3:13] # get climate & MEM variables\n\n# build individual SNP datasets\nSNPs_ref &lt;- gfData[,grep(\"REFERENCE\",colnames(gfData))] # reference 360 loci\nGI5 &lt;- gfData[,grep(\"GI5\",colnames(gfData))] # GIGANTEA-5 (GI5)\n\nmaxLevel &lt;- log2(0.368*nrow(envGF)/2) #account for correlations, F&K set this flag but do not explain beyond saying \"see ?gradientForest\"\n\n# Fit gf models for reference SNPs \ngfRef &lt;- gradientForest(cbind(envGF, SNPs_ref), predictor.vars=colnames(envGF), response.vars=colnames(SNPs_ref), ntree=500, maxLevel=maxLevel, trace=T, corr.threshold=0.50)\n\n# Fit gf models for GI5 SNPs\ngfGI5 &lt;- gradientForest(cbind(envGF, GI5), predictor.vars=colnames(envGF),\n                          response.vars=colnames(GI5), ntree=500, \n                          maxLevel=maxLevel, trace=T, corr.threshold=0.50)\n\n# plot output, see ?plot.gradientForest\n\nplot(gfRef, plot.type=\"O\") # values that feed into Fig1\nplot(gfRef, plot.type = \"C\")  # Fig2 \nplot(gfRef, plot.type = \"S\")\n\n     \n#can do the same for GI5"
  },
  {
    "objectID": "genetic-dif.html",
    "href": "genetic-dif.html",
    "title": "Genetic differentiation",
    "section": "",
    "text": "Describing genetic differentiation and genetic structuring\n\nlibrary(tidyverse)\n\n\nInvestigating population structure with PCA\nThe first thing we will do is investigate population structure using principal components analysis. Examining population structure can give us a great deal of insight into the history and origin of populations. Model-free methods for examining population structure and ancestry, such as principal components analysis are extremely popular in population genomic research. This is because it is typically simple to apply and relatively easy to interpret.\nEssentially, PCA aims to identify the main axes of variation in a dataset with each axis being independent of the next (i.e. there should be no correlation between them). The first component summarizes the major axis variation and the second the next largest and so on, until cumulatively all the available variation is explained. In the context of genetic data, PCA summarizes the major axes of variation in allele frequencies and then produces the coordinates of individuals along these axes.\nTo perform a PCA on our cichlid data, we will use plink - specifically version 1.9 (although be aware older and newer versions are available). Note that plink was originally written with human data in mind and has also subsequently been extended to include some model species. As a result, we need to provide a bit of extra info to get it to work on our dataset.\n\nLinkage pruning\nOne of the major assumptions of PCA is that the data we use is indpendent - i.e. there are no spurious correlations among the measured variables. This is obviously not the case for most genomic data as allele frequencies are correlated due to physical linkage and linkage disequilibrium. So as a first step, we need to prune our dataset of variants that are in linkage.\nFirst things first, we will make a directory called pca\n# move to your home directory\ncd ~\n# make a pca directory\nmkdir pca\n# move into it\ncd pca\nNext we need to get our data, which we can do like so:\ncp /resources/riverlandsea/exercise_data/pca/Pundamilia_subset.vcf.gz .\nWe will also simplify our code using some environmental variables. Primarily we set one for our filtered VCF.\nVCF=~/pca/Pundamilia_subset.vcf.gz\nThis will make it very easy for plink to read in our data. Next we run the linkage pruning. Run the command and we will breakdown what all the arguments mean.\n# perform linkage pruning - i.e. identify prune sites\nplink --vcf $VCF --double-id --allow-extra-chr \\\n--set-missing-var-ids @:# \\\n--indep-pairwise 50 10 0.1 --out cichlids\nSo for our plink command, we did the following:\n\n--vcf - specified the location of our VCF file.\n--double-id - told plink to duplicate the id of our samples (this is because plink typically expects a family and individual id - i.e. for pedigree data - this is not necessary for us.\n--allow-extra-chr - allow additional chromosomes beyond the human chromosome set. This is necessary as otherwise plink expects chromosomes 1-22 and the human X chromosome.\n--set-missing-var-ids - also necessary to set a variant ID for our SNPs. Human and model organisms often have annotated SNP names and so plink will look for these. We do not have them so instead we set ours to default to chromosome:position which can be achieved in plink by setting the option @:# - see here for more info.\n--indep-pairwise - finally we are actually on the command that performs our linkage pruning! The first argument, 50 denotes we have set a window of 50 Kb. The second argument, 10 is our window step size - meaning we move 10 bp each time we calculate linkage. Finally, we set an r2 threshold - i.e. the threshold of linkage we are willing to tolerate. Here we prune any variables that show an r2 of greater than 0.1.\n--out Produce the prefix for the output data.\n\nAs well as being versatile, plink is very fast. It will quickly produce a linkage analysis for all our data and write plenty of information to the screen. When complete, it will write out two files cichlids.prune.in and cichlids.prune.out. The first of these is a list of sites which fell below our linkage threshold - i.e. those we should retain. The other file is the opposite of this. In the next step, we will produce a PCA from these linkage-pruned sites.\n\n\nPerform a PCA\nNext we rerun plink with a few additional arguments to get it to conduct a PCA. We will run the command and then break it down as it is running.\n# prune and create pca\nplink --vcf $VCF --double-id --allow-extra-chr --set-missing-var-ids @:# \\\n--extract cichlids.prune.in \\\n--make-bed --pca --out cichlids\nThis is very similar to our previous command. What did we do here?\n\n--extract - this just lets plink know we want to extract only these positions from our VCF - in other words, the analysis will only be conducted on these.\n--make-bed - this is necessary to write out some additional files for another type of population structure analysis - a model based approach with admixture.\n--pca - fairly self explanatory, this tells plink to calculate a principal components analysis.\n\nOnce the command is run, we will see a series of new files. We will break these down too:\nPCA output:\n\ncichlids.eigenval - the eigenvalues from our analysis\ncichlids.eigenvec- the eigenvectors from our analysis\n\nplink binary output\n\ncichlids.bed - the cichlids bed file - this is a binary file necessary for admixture analysis. It is essentially the genotypes of the pruned dataset recoded as 1s and 0s.\ncichlids.bim - a map file (i.e. information file) of the variants contained in the bed file.\n\ncichlids.fam - a map file for the individuals contained in the bed file.\n\n\n\nPlotting the PCA output\nNext we turn to R to plot the analysis we have produced!\n\nSetting up the R environment\nFirst load the tidyverse package and ensure you have moved the plink output into the working directory you are operating in. You may want to set up an RStudio Project to manage this analysis. See here for a guide on how to do this.\n\n# load tidyverse package\nlibrary(tidyverse)\n\nThen we will use a combination of readr and the standard scan function to read in the data. NB - you will need to edit the path to the files if you are writing your own R scripts.\n\npca &lt;- read_table(\"./data/cichlids.eigenvec\", col_names = FALSE)\neigenval &lt;- scan(\"./data/cichlids.eigenval\")\n\n\n\nCleaning up the data\nUnfortunately, we need to do a bit of legwork to get our data into reasonable shape. First we will remove a nuisance column (plink outputs the individual ID twice). We will also give our pca data.frame proper column names.\n\n# sort out the pca data\n# remove nuisance column\npca &lt;- pca[,-1]\n# set names\nnames(pca)[1] &lt;- \"ind\"\nnames(pca)[2:ncol(pca)] &lt;- paste0(\"PC\", 1:(ncol(pca)-1))\n\nNext we can add a species, location and if required, a species x location vector. We will do this using the R version of grep. We then use paste0 to combine the columns.\n\n# sort out the individual species and pops\n# spp\nspp &lt;- rep(NA, length(pca$ind))\nspp[grep(\"PunPund\", pca$ind)] &lt;- \"pundamilia\"\nspp[grep(\"PunNyer\", pca$ind)] &lt;- \"nyererei\"\n# location\nloc &lt;- rep(NA, length(pca$ind))\nloc[grep(\"Mak\", pca$ind)] &lt;- \"makobe\"\nloc[grep(\"Pyt\", pca$ind)] &lt;- \"python\"\n# combine - if you want to plot each in different colours\nspp_loc &lt;- paste0(spp, \"_\", loc)\n\nWith these variables created, we can remake our data.frame like so. Note the use of as.tibble to ensure that we make a tibble for easy summaries etc.\n\n# remake data.frame\npca &lt;- as_tibble(data.frame(pca, spp, loc, spp_loc))\n\n\n\nPlotting the data\nNow that we have done our housekeeping, we have everything in place to actually visualise the data properly. First we will plot the eigenvalues. It is quite straightforward to translate these into percentage variance explained (although note, you could just plot these raw if you wished).\n\n# first convert to percentage variance explained\npve &lt;- data.frame(PC = 1:20, pve = eigenval/sum(eigenval)*100)\n\nWith that done, it is very simple to create a bar plot showing the percentage of variance each principal component explains.\n\n# make plot\na &lt;- ggplot(pve, aes(PC, pve)) + geom_bar(stat = \"identity\")\na + ylab(\"Percentage variance explained\") + theme_light()\n\nCumulatively, they explain 100% of the variance but PC1, PC2 and possible PC3 together explain about 30% of the variance. We could calculate this with the cumsum function, like so:\n\n# calculate the cumulative sum of the percentage variance explained\ncumsum(pve$pve)\n\nNext we move on to actually plotting our PCA. Given the work we did earlier to get our data into shape, this doesn’t take much effort at all.\n\n# plot pca\nb &lt;- ggplot(pca, aes(PC1, PC2, col = spp, shape = loc)) + geom_point(size = 3)\nb &lt;- b + scale_colour_manual(values = c(\"red\", \"blue\"))\nb &lt;- b + coord_equal() + theme_light()\nb + xlab(paste0(\"PC1 (\", signif(pve$pve[1], 3), \"%)\")) + ylab(paste0(\"PC2 (\", signif(pve$pve[2], 3), \"%)\"))\n\nNote that this R code block also includes arguments to display the percentage of variance explained on each axis. Here we only plot PC1 and PC2. From this figure, we can see PC1 separates out the geographical locations and PC2 separates out the species.\n\n\n\n\nAdmixture\nADMIXTURE is a clustering software similar to STRUCTURE with the aim of inferring populations and individual ancestries. It was developed by David Alexander, John Novembre and Kenneth Lange. You can find the manual here.\n\nGenerating the input file\nADMIXTURE requires unlinked (i.e. LD-pruned) SNPs in the format that plink writes out. As we saw in the last practical, this is very easy to produce from a VCF. However when we were producing a PCA, we used a vcf with only whole-genome resequenced individuals (i.e. a much smaller sample size). So for this practical we will use a RAD dataset from the same Pundamilia species which includes more than 4 individuals per population and some putative hybrid individuals.\nLinked sites, monomorphic or multiallelic sites, or sites with more than 25% missing data have already been filtered out. Also sites with MAF smaller than 0.05 or Phred quality lower than 30 were removed. So there is no need to redo the filtering or linkage-pruning we learned about earlier. We proceed to uisng plink to generate the .bed file which can be read by ADMIXTURE (nb it will also produce other files we do not need).\nFirst we will make a directory specific for this analysis in our home directory and move into it:\n# move to your home directory\ncd ~\n# make a pca directory\nmkdir admixture\n# move into it\ncd admixture\nNext we need to get our data, which we can do like so:\ncp /resources/riverlandsea/exercise_data/admixture/Pundamilia.RAD.vcf.gz .\nAs before, we will simplify our code using some environmental variables. Primarily we set one for our filtered VCF.\nVCF=~/admixture/Pundamilia.RAD.vcf.gz\nWe can also create one to make it easier to create an output file from plink and to perform our downstream tweaks to the file to get it to work with ADMIXTURE\nFILE=Pundamilia.RAD\nNow we are ready to use plink to generate the input file that we will use in our analysis.\n# Generate the input file in plink format\nplink --vcf $VCF --make-bed --out $FILE --allow-extra-chr\nOnce we’ve run this, use ls to have a look at the files written out. An important note. The PLINK bed file is a binary biallelic genotype table (not to be confused with UCSC bed files).\nLike with many tools, we have to do a bit of coding in order to get a file in a suitable shape for a downstream analysis. ADMIXTURE does not accept chromosome names that are not human chromosomes. We therefore need to change the first column with 0. We can do this relatively easily with awk. We make a temporary file and when we’re sure it is how we want it to look, we can move it to become our new input file.\nawk '{$1=\"0\";print $0}' $FILE.bim &gt; $FILE.bim.tmp\nmv $FILE.bim.tmp $FILE.bim\n\n\nRunning ADMIXTURE\nNow, we are ready to run ADMIXTURE. An important step is to run the program with cross-validation. This allows us to determine the error in our estimates of K, providing insight into what the ‘true’ value of K might be. We will first run the program to test a K of 2.\nadmixture --cv $FILE.bed 2 &gt; log2.out\nNote that here we just the default CV option, which is for 5 times cross validation. IF you want to increase this, you can set an option like so cv=10.\nLooking at our directory, we can see that ADMIXTURE produced 2 files: .Q which contains cluster assignments for each individual and .P which contains for each SNP the population allele frequencies.\nLet’s now run it in a for loop with K=3 to K=5 and direct the output into log files.\nfor i in {3..5}\ndo\n admixture --cv $FILE.bed $i &gt; log${i}.out\ndone\nTo identify the best value of K clusters which is the value with lowest cross-validation error, we need to collect the cv error output into a single files. Combining awk and cut, we can easily extract them like so:\n\ngrep \"CV\" *out | awk '{print $3,$4}' | cut -c 4,7-20 &gt; $FILE.cv.error\nTo make plotting easier, we can also make a file with the individual names in one column and the species names in the second column. As the species name is in the individual name, it is very straightforward to extract the species name from the individual name using awk:\nawk '{split($1,name,\".\"); print $1,name[2]}' $FILE.nosex &gt; $FILE.list\nNow we’ve performed our analyses, we are ready to visualise the results.\n\nVisualising results using R\nThere are many different ways to plot ADMIXTURE output and other tutorials go into this in more detail (e.g., this is nice and clear). There are also specific programs i.e.pong. However, to make things easy for today’s practical, we will use an R written by Joana Meier.\nThis script can be used via the command line and takes four arguments: 1. the prefix for the ADMIXTURE output files (-p ) 2. the file with the species information (-i &lt;file.list&gt;) 3. the maximum number of K to be plotted (-k 5) 4. a list with the populations or species separated by commas (-l &lt;pop1,pop2…&gt;)\nThis last option, i.e. the list of populations provided with -l gives the order in which the populations or species will be plotted. The script is available here but for today, we can also get it from the data directory:\ncp /resources/riverlandsea/exercise_data/admixture/plotADMIXTURE.r .\nNow, we can run it like below. Remember our $FILE variable makes it much easier to run without inputting the full filenames.\nRscript plotADMIXTURE.r -p $FILE -i $FILE.list -k 5 -l PunNyerMak,PunPundMak,PunNyerPyt,PunHybrPyt,PunPundPyt\nBy default, the script generates a tiff file that uses the same prefix as the one provided with -p. In our case $FILE.tiff. This can be changed with -o\n\nif necessary, but for now we will keep it as it is.\nTo examine the file, you need to download it to your local machine using either scp (Mac OS, Linux) or an scp client such as filezilla.\n\n\n\nSome points to keep in mind\nRemember that ADMIXTURE/STRUCTURE plots can be quite misleading as different demographic histories can lead to the same results (see. e.g. Lawson et al, 2018) These plots are great to detect recent hybrids but they are not ideal to infer complex demographic histories with hybrid origins of entire populations\nTo evaluate if the ADMIXTURE plot is a good fit, you can use evaladmix and we highly recommend to also use other methods to help infer the demographic history and evidence of hybridisation such as independent tests of gene flow or demographic analyses."
  },
  {
    "objectID": "resistance.html",
    "href": "resistance.html",
    "title": "Resistance surfaces",
    "section": "",
    "text": "Installation instruction - resistance GA for the Thursday morning session on resistance surfaces\nTo install on your own computer before Thursday - see instructions"
  }
]